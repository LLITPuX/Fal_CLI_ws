# Backend Configuration
# HOST_GEMINI_DIR=C:\Users\YourUser\.gemini
# GEMINI_CLI=gemini

# Default Gemini model (used when request doesn't override)
GEMINI_MODEL=gemini-2.5-flash

# Comma-separated list of allowed models exposed to the API.
# Keep this list in sync with the frontend selector.
# Example (paid tier required for pro): gemini-2.5-flash,gemini-2.5-pro
GEMINI_MODELS=gemini-2.5-flash
GOOGLE_CLOUD_PROJECT=your-actual-gcp-project-id

# OpenAI API (for Subconscious Agent - Phase 2)
OPENAI_API_KEY=your-openai-api-key-here

API_PORT=8000

# Frontend Configuration
FRONTEND_PORT=3000

# Default model pre-selected in the UI (must match an allowed backend model)
VITE_GEMINI_MODEL=gemini-2.5-flash

# FalkorDB Configuration
FALKORDB_HOST=falkordb
FALKORDB_PORT=6379
FALKORDB_GRAPH_NAME=gemini_graph
FALKORDB_MAX_QUERY_TIME=30

# Available Gemini Models (Free Tier):
# - gemini-2.5-flash (recommended - 15 RPM, good quality)
# - gemini-2.5-pro (paid tier only - 2 RPM, daily limits)
