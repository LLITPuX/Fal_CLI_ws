---
description: Testing and debugging best practices for Cursor AI development
alwaysApply: false
---
# TESTING RULES

## Purpose

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ´Ğ»Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ½Ğ¾Ğ²Ğ¸Ñ… features Ğ· Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½ÑĞ¼ Playwright, Context7, Docker logs Ñ‚Ğ° Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ–Ğ² Ğ´Ñ–Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸.

**Based on:** Phase 2 Subconscious Agent implementation (Nov 10, 2025)

---

## Testing Philosophy

**"Code â†’ Test â†’ Debug â†’ Verify â†’ Commit"**

### ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¸:

1. **Test Early** - Ñ‚ĞµÑÑ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ²Ñ–Ğ´Ñ€Ğ°Ğ·Ñƒ Ğ¿Ñ–ÑĞ»Ñ Ñ–Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—, Ğ½Ğµ Ñ‡ĞµĞºĞ°Ñ‚Ğ¸ "Ğ·Ğ°ĞºÑ–Ğ½Ñ‡ĞµĞ½Ğ½Ñ"
2. **Test Realistically** - Ñ‡ĞµÑ€ĞµĞ· Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€ (Playwright), Ğ½Ğµ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ unit tests
3. **Debug Systematically** - Context7 Ğ´Ğ»Ñ Ñ€Ğ¾Ğ·ÑƒĞ¼Ñ–Ğ½Ğ½Ñ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº, logs Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ğ½Ğ³Ñƒ
4. **Verify Data** - Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° ÑÑ‚Ğ°Ğ½Ñƒ Ğ‘Ğ” Ğ¿Ñ–ÑĞ»Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ñ–Ğ¹
5. **Document Bugs** - ĞºĞ¾Ğ¶ĞµĞ½ bug = learning opportunity

**ĞœĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ°:** Ğ¢ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ ÑĞº ĞºĞ¾Ğ·Ğ°Ñ†ÑŒĞºĞ¸Ğ¹ Ğ´Ğ¾Ğ·Ğ¾Ñ€ - Ğ¿Ğ¾ÑÑ‚Ñ–Ğ¹Ğ½Ğ° Ğ¿Ğ¸Ğ»ÑŒĞ½Ñ–ÑÑ‚ÑŒ Ğ½Ğ° ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ¼Ñƒ ĞµÑ‚Ğ°Ğ¿Ñ–.

---

## Testing Workflow (8 Phases)

### Phase 1: Pre-Test Validation

**Checklist Ğ¿ĞµÑ€ĞµĞ´ Ñ‚ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼:**
- [ ] Ğ’ÑÑ– Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ– ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ñ– Ñ‚Ğ° Ñ–Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²Ğ°Ğ½Ñ–
- [ ] `read_lints` - no errors
- [ ] Dependencies Ğ´Ğ¾Ğ´Ğ°Ğ½Ñ– Ğ² requirements.txt
- [ ] Config variables Ğ² core/config.py
- [ ] Integration Ğ² workflow (graph.py, main.py)
- [ ] Documentation updated (.mdc files)

**Tools:**
```python
read_lints(["path/to/module"])
grep("pattern", path="backend/app")
```

### Phase 2: Build & Deploy

```powershell
# Rebuild Ğ· Ğ½Ğ¾Ğ²Ğ¸Ğ¼ ĞºĞ¾Ğ´Ğ¾Ğ¼
docker compose build [service]

# Restart containers
docker compose up -d

# Wait for initialization
Start-Sleep -Seconds 5

# Verify status
docker compose ps
```

**Expected output:**
```
NAME              STATUS
gemini-backend    Up X seconds (healthy)
gemini-frontend   Up X seconds
gemini-falkordb   Up X seconds (healthy)
```

**Red flags:**
- âŒ `Exit X` Ğ°Ğ±Ğ¾ `Restarting`
- âŒ No "(healthy)" status Ğ¿Ñ–ÑĞ»Ñ 10s
- âŒ Container missing

**If failed:**
```powershell
docker compose logs [service] --tail 50
```

### Phase 3: Initial Playwright Test

**Strategy:**
1. Navigate Ğ´Ğ¾ relevant page
2. Perform user action (type, click, submit)
3. Wait for processing
4. Capture state
5. Check for errors

**Example flow:**
```javascript
// 1. Navigate
await browser_navigate("http://localhost:3000/chat")

// 2. Wait for load
await browser_wait_for(seconds=2)

// 3. Snapshot to get element refs
await browser_snapshot()

// 4. Type message
await browser_type(
    element="textarea Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ",
    ref="e44",
    text="Test message",
    submit=true
)

// 5. Wait for processing
await browser_wait_for(seconds=5)

// 6. Check console
// Look for: [ERROR] in console messages
```

**Success indicators:**
- âœ… No console [ERROR]
- âœ… Message appears in UI
- âœ… Loading indicator works
- âœ… Response appears

**Failure indicators:**
- âŒ HTTP 500 error
- âŒ "Failed to send message" console error
- âŒ Infinite loading
- âŒ Empty response

### Phase 4: Analyze Logs

**When test fails, analyze logs systematically:**

```powershell
# Get recent logs with context
docker compose logs backend --tail 100

# Filter by agent
docker compose logs backend | Select-String -Pattern "ğŸ“|ğŸ§ |ğŸ¯"

# Filter errors with context
docker compose logs backend --tail 200 | Select-String -Pattern "ERROR|Traceback|Exception" -Context 5

# Follow live logs
docker compose logs backend --follow
```

**Log analysis pattern:**
```
1. Find ERROR or Traceback
2. Read error message
3. Note file:line number
4. Read context (5 lines before)
5. Identify root cause
```

**Example from today:**
```
ERROR: 'content'
Traceback:
  File "repository.py", line 147, in get_all_chunks
    chunk = self._row_to_chunk(r["c"])
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  KeyError: 'content'
```

**Analysis:**
- File: repository.py, line 147
- Function: get_all_chunks_with_embeddings
- Problem: Accessing r["c"] as dict but it's a node object
- Solution: Query should return properties explicitly

### Phase 5: Use Context7 for Understanding

**When to use Context7:**

**Scenario A: Understanding Working Patterns**
```
Query: "How does Clerk query FalkorDB and parse results?"
Purpose: Learn proven patterns
Action: Copy working approach to new code
```

**Scenario B: Finding All Usages**
```
Query: "Where is ChatState modified in the workflow?"
Purpose: Understand state flow
Action: Verify state contract consistency
```

**Scenario C: Debugging Unknown Errors**
```
Query: "What does AsyncClient 'proxies' parameter do in OpenAI?"
Purpose: Understand dependency issue
Action: Find compatible versions
```

**Scenario D: Consistency Check**
```
Query: "How do other agents handle DatabaseError exceptions?"
Purpose: Follow established patterns
Action: Apply same error handling
```

**Context7 workflow:**
1. Read error message
2. Identify unclear part (function, parameter, pattern)
3. Ask Context7 about working examples
4. Compare your code with working code
5. Identify difference
6. Apply fix

### Phase 6: Fix and Rebuild

**Incremental fixing:**

```
1. Fix ONE issue
2. git add [file]
3. docker compose build
4. docker compose up -d
5. Re-test
6. If works â†’ commit
7. If not â†’ repeat
```

**DON'T fix multiple issues at once!**

**Example from today:**
```
Bug 1: httpx version incompatibility
  â†’ Fixed requirements.txt
  â†’ Rebuild
  â†’ Test â†’ Still error

Bug 2: State message not found
  â†’ Fixed nodes.py (use state directly)
  â†’ Rebuild
  â†’ Test â†’ Still error

Bug 3: FalkorDB query format
  â†’ Fixed repository.py (return properties)
  â†’ Rebuild
  â†’ Test â†’ SUCCESS!
```

Each fix tested separately = clear understanding what worked.

### Phase 7: Verify in Database

**After successful test, verify data persisted correctly:**

```powershell
# Count created nodes
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (n:Chunk) RETURN count(n)"

# Inspect node properties
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (c:Chunk) RETURN c.id, c.content, c.chunk_type LIMIT 5"

# Check relationships
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (c1)-[r:SIMILAR_TO]->(c2) RETURN c1.content, c2.content, r.similarity"

# Verify entities
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (e:Entity) RETURN e.name, e.type, e.mention_count"

# Full graph statistics
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (n) RETURN labels(n)[0] as type, count(n) as count ORDER BY count DESC"

docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH ()-[r]->() RETURN type(r) as rel_type, count(r) as count ORDER BY count DESC"
```

**Validation checklist:**
- [ ] Expected number of nodes created
- [ ] Properties filled correctly (not NULL)
- [ ] Relationships exist between nodes
- [ ] Relationship properties valid (e.g., similarity 0.0-1.0)
- [ ] Temporal fields set (valid_at, created_at)
- [ ] No duplicate nodes (unless expected)

### Phase 8: Regression Testing

**Test Ñ‰Ğ¾ ÑÑ‚Ğ°Ñ€Ñ– features Ñ‰Ğµ Ğ¿Ñ€Ğ°Ñ†ÑÑÑ‚ÑŒ:**

```javascript
// Test 1: Clerk still works alone
browser_type("Simple message", submit=true)
// Verify: Message recorded in DB

// Test 2: Multiple messages
for (let i = 0; i < 3; i++) {
    browser_type(`Message ${i}`, submit=true)
    browser_wait_for(3)
}
// Verify: All messages in DB, relationships created

// Test 3: Different topics
browser_type("Docker containers", submit=true)
browser_wait_for(5)
browser_type("Ukrainian history", submit=true)
browser_wait_for(5)
// Verify: Low similarity (different topics)

// Test 4: Same topic
browser_type("Docker images and volumes", submit=true)
browser_wait_for(5)
// Verify: High similarity found
```

---

## Common Bug Patterns & Solutions

### Bug Pattern 1: Version Incompatibility

**Symptom:**
```
TypeError: AsyncClient.__init__() got unexpected keyword argument 'proxies'
ImportError: cannot import name 'X' from 'Y'
```

**Diagnosis:**
- Dependency version conflict
- API changed between versions
- Missing intermediate dependency

**Solution:**
```python
# 1. Check compatibility matrix
# OpenAI 1.54 requires httpx <0.28

# 2. Pin both versions
openai==1.54.3
httpx==0.27.2

# 3. Rebuild
docker compose build backend
```

**Context7 query:**
```
"What httpx version is compatible with openai 1.54?"
"How do other Python projects handle OpenAI dependencies?"
```

**Prevention:**
- Pin all major dependencies
- Document known conflicts
- Test after adding new deps

### Bug Pattern 2: State Shape Mismatch

**Symptom:**
```
KeyError: 'message_id'
ValueError: expected field not found in state
AttributeError: 'dict' object has no attribute 'X'
```

**Diagnosis:**
- Previous agent didn't set expected field
- State contract violated
- Dict vs Pydantic object confusion

**Solution:**
```python
# 1. Check what previous agent provides
# Clerk sets: message_id, recorded, message_content

# 2. Use state directly, don't re-fetch
message_content = state.get("message_content")  # âœ…
# Not: message = await repo.get_message(id)      # âŒ

# 3. Validate at entry
if not state.get("recorded"):
    return state  # Skip processing
```

**Context7 query:**
```
"What fields does Clerk add to ChatState?"
"Where is state modified in the workflow?"
```

**Prevention:**
- Document state contract in state.py
- Validate required fields at node entry
- Use type hints and Pydantic

### Bug Pattern 3: Database Query Format

**Symptom:**
```
KeyError: 'content'
DatabaseError: Expected dict, got object
TypeError: object is not subscriptable
```

**Diagnosis:**
- FalkorDB returns different format than expected
- Returning full node vs properties
- Missing property aliases

**Solution:**
```cypher
-- âŒ WRONG - returns node object
MATCH (c:Chunk)
RETURN c

-- âœ… CORRECT - returns individual properties
MATCH (c:Chunk)
RETURN c.id as id, c.content as content, c.position as position

-- Pattern: Always return named properties
```

**Context7 query:**
```
"How does Clerk query FalkorDB nodes?"
"What is the structure of FalkorDB query results?"
```

**Prevention:**
- Follow Clerk query patterns (proven)
- Always alias properties (`as name`)
- Test queries in redis-cli first
- Document expected row structure

### Bug Pattern 4: Async/Await Missing

**Symptom:**
```
RuntimeWarning: coroutine was never awaited
TypeError: object is not awaitable
```

**Diagnosis:**
- Forgot `await` on async function
- Mixing sync/async code
- Calling async from sync context

**Solution:**
```python
# âŒ WRONG
result = async_function()  # Returns coroutine

# âœ… CORRECT
result = await async_function()  # Executes and returns value
```

**Prevention:**
- All I/O operations MUST be async
- Add type hints: `async def function() -> Type:`
- Enable pylint async checks

### Bug Pattern 5: F-String Complexity

**Symptom:**
```
SyntaxError: invalid syntax in f-string
ZeroDivisionError: division by zero
```

**Diagnosis:**
- Complex expression in f-string
- Conditional with multiple operators
- Division without zero check

**Solution:**
```python
# âŒ WRONG - complex conditional in f-string
f"{sum(x) / len(x) if x else 0:.3f}"

# âœ… CORRECT - calculate first
avg = sum(x) / len(x) if x else 0.0
f"{avg:.3f}"
```

**Prevention:**
- Extract complex logic to variables
- Keep f-strings simple (formatting only)
- Test edge cases (empty lists, None values)

### Bug Pattern 6: Graceful Degradation Missing

**Symptom:**
```
System crashes completely when one component fails
500 error stops entire pipeline
```

**Diagnosis:**
- No try-except in critical sections
- Exceptions bubble up unhandled
- No fallback behavior

**Solution:**
```python
try:
    context = await build_full_context(...)
except EmbeddingError:
    # Fallback: basic context
    logger.warning("Embeddings failed, using basic context")
    context = ContextAnalysis()  # Empty but valid
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    context = ContextAnalysis()  # Always return valid object

# State always updated, system continues
state["context"] = context.model_dump()
state["analyzed"] = True  # Mark as processed even if degraded
```

**Prevention:**
- Try-except at node level
- Always return valid state object
- Log degradation warnings
- System continues even with partial failure

---

## Testing Workflow Step-by-Step

### âœ… Phase 1: Pre-Test Validation

**Run these checks:**
```python
# 1. Linter check
read_lints(["backend/app/agents/subconscious"])

# 2. Import check
grep("from app.agents.subconscious", path="backend/")

# 3. Config check
read_file("backend/app/core/config.py")
# Verify: openai_api_key, subconscious_* settings exist
```

**Expected:** No errors, all imports found, config complete

### âœ… Phase 2: Build & Deploy

```powershell
# Clean rebuild
docker compose build backend --no-cache  # If major changes

# Or quick rebuild
docker compose build backend

# Start
docker compose up -d

# Check startup logs
docker compose logs backend --tail 30

# Wait for initialization
Start-Sleep -Seconds 10

# Verify healthy
docker compose ps
```

**Expected logs:**
```
âœ… FalkorDB initialized
âœ… Multi-agent chat system (Phase X) initialized
âœ… Application startup complete
```

### âœ… Phase 3: Browser Test (Playwright)

```javascript
// Step 1: Navigate
browser_navigate("http://localhost:3000/chat")
// Expected: Session created log

// Step 2: Snapshot
browser_snapshot()
// Get: element refs

// Step 3: Type test message
browser_type(
    element="textarea",
    ref="eXX",  // from snapshot
    text="Test: Docker containerization platform",
    submit=true
)

// Step 4: Wait for processing
browser_wait_for(seconds=8)  // Subconscious ~5s

// Step 5: Check result
browser_snapshot()
// Expected: Message appears in chat

// Step 6: Check console
// Look for [ERROR] messages
```

**Success criteria:**
- âœ… No [ERROR] in console
- âœ… Message visible in UI
- âœ… No infinite loading
- âœ… Response received (Ğ´Ğ°Ğ¶Ğµ mock)

### âœ… Phase 4: Log Analysis

**When error occurs:**

```powershell
# Get full context
docker compose logs backend --tail 150 > test_error.log

# Open for analysis
notepad test_error.log

# Or filter immediately
docker compose logs backend --tail 200 | Select-String -Pattern "ERROR|Traceback|ğŸ§ " -Context 3
```

**What to extract:**
1. **Error type:** `KeyError`, `ValueError`, `DatabaseError`
2. **File and line:** `repository.py:147`
3. **Function:** `get_all_chunks_with_embeddings`
4. **Error message:** `'content'`
5. **Agent context:** `ğŸ§  ĞŸÑ–Ğ´ÑĞ²Ñ–Ğ´Ğ¾Ğ¼Ñ–ÑÑ‚ÑŒ` emoji
6. **Before error:** What happened 3-5 log lines before?

**Create mental model:**
```
User clicked Send
  â†’ Frontend POST /api/chat/message
    â†’ Clerk Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ² (SUCCESS âœ…)
      â†’ Subconscious started (ğŸ§ )
        â†’ Step 1: Chunking (SUCCESS âœ…)
        â†’ Step 2: Embeddings (SUCCESS âœ…)
        â†’ Step 3: Entities (SUCCESS âœ…)
        â†’ Step 4: Similarity search (FAILED âŒ)
          â†’ get_all_chunks_with_embeddings
            â†’ KeyError: 'content'
```

### âœ… Phase 5: Context7 Investigation

**Use Context7 to understand the issue:**

**Query 1: Find working pattern**
```
"How does Clerk query FalkorDB and extract node properties?"
```

**Response analysis:**
- Clerk uses: `RETURN m.id as id, m.content as content`
- Returns individual properties, not full node
- Accesses row["id"], row["content"]

**Query 2: Verify understanding**
```
"What is the format of FalkorDB query results?"
```

**Response analysis:**
- Results = list of dicts
- Each dict has named fields from RETURN clause
- Node objects require property access

**Query 3: Find all call sites**
```
"Where is get_all_chunks_with_embeddings called?"
```

**Response analysis:**
- Called from similarity_searcher in nodes.py
- Expects list[Chunk] with embeddings
- Used in loop: `for c in chunks: c.embedding`

### âœ… Phase 6: Apply Fix

**Fix strategy:**
1. **Copy working pattern** (Clerk query style)
2. **Change ONE thing**
3. **Verify change** (re-read file)
4. **Comment why** (if non-obvious)

**Example fix:**
```python
# Before (WRONG)
cypher = "MATCH (c:Chunk) RETURN c"
chunk = self._row_to_chunk(r["c"])

# After (CORRECT - copied Clerk pattern)
cypher = """
MATCH (c:Chunk)
RETURN c.id as id, c.content as content, c.position as position
"""
chunk = Chunk(
    id=row["id"],
    content=row["content"],
    position=row["position"],
    # ...
)
```

**Rebuild and test:**
```powershell
docker compose build backend
docker compose up -d
# Re-run browser test
```

### âœ… Phase 7: Database Verification

**After successful test, verify data integrity:**

**Node counts:**
```powershell
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (n) RETURN labels(n)[0] as type, count(n) as count"
```

**Expected:**
```
Messages: X (Ğ¾Ğ´Ğ¸Ğ½ Ğ½Ğ° ĞºĞ¾Ğ¶ĞµĞ½ user + assistant message)
Chunks: Y (Ğ·Ğ°Ğ»ĞµĞ¶Ğ¸Ñ‚ÑŒ Ğ²Ñ–Ğ´ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€Ñƒ messages)
Entities: Z (Ğ²Ğ¸Ñ‚ÑĞ³Ğ½ÑƒÑ‚Ñ– entities)
```

**Property validation:**
```powershell
# Check embeddings exist
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (c:Chunk) WHERE c.embedding IS NOT NULL RETURN count(c)"

# Check entity normalization
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (e:Entity {type: 'TECH'}) RETURN e.name, e.canonical_name"
```

**Expected:**
- âœ… All chunks have embeddings (arrays of 1536 floats)
- âœ… Entity canonical_names lowercase
- âœ… No NULL in required fields

**Relationship validation:**
```powershell
# Chunks linked to messages
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH (c:Chunk)-[:PART_OF]->(m:Message) RETURN count(c)"

# Similarity edges
docker exec gemini-falkordb redis-cli GRAPH.QUERY gemini_graph "MATCH ()-[r:SIMILAR_TO]->() RETURN r.similarity"
```

**Expected:**
- âœ… Every chunk has PART_OF relationship
- âœ… Similarity scores 0.7-1.0 (above threshold)
- âœ… No self-references

### âœ… Phase 8: Edge Cases

**Test boundary conditions:**

**Test 1: Empty/Short Input**
```javascript
browser_type("Hi", submit=true)
```
Expected: No crash, minimal context

**Test 2: Very Long Input**
```javascript
browser_type("[5000+ chars text]", submit=true)
```
Expected: Multiple chunks created, semantic splitting

**Test 3: Special Characters**
```javascript
browser_type("Test <>&\"' special chars", submit=true)
```
Expected: Proper escaping, no injection

**Test 4: Code Blocks**
```javascript
browser_type("```python\ndef hello():\n    print('hi')\n```", submit=true)
```
Expected: Detected as 'code' chunk_type

**Test 5: Mixed Languages**
```javascript
browser_type("Docker Ñ†Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ñ–Ñ plus English words", submit=true)
```
Expected: Language detection, proper entities

---

## Performance Testing

### Timing Measurements

**Add to code during development:**
```python
import time

start = time.time()
# ... operation ...
elapsed_ms = (time.time() - start) * 1000
logger.info(f"â±ï¸ [operation_name] took {elapsed_ms:.0f}ms")
```

**Expected timings:**

| Operation | Target | Acceptable | Warning |
|-----------|--------|------------|---------|
| Clerk record | <20ms | <50ms | >100ms |
| Semantic chunking | <30ms | <100ms | >200ms |
| OpenAI embeddings | <500ms | <2s | >5s |
| Entity extraction | <1s | <3s | >5s |
| Similarity search | <100ms | <300ms | >1s |
| Graph writes | <100ms | <300ms | >1s |
| **Subconscious total** | <2s | <5s | >10s |

**If slower than warning:**
1. Check logs for bottleneck
2. Profile with timing logs
3. Optimize hot path
4. Consider caching/batching

### Load Testing

**For production readiness:**

```powershell
# Send multiple messages quickly
for ($i=1; $i -le 10; $i++) {
    # API call or browser automation
    Start-Sleep -Milliseconds 500
}
```

**Monitor:**
- Memory usage: `docker stats`
- Database size: `GRAPH.QUERY "MATCH (n) RETURN count(n)"`
- Response times: logs
- Error rate: logs

---

## Context7 Integration Patterns

### Pattern 1: Learning from Working Code

**Situation:** Need to implement feature X, similar exists in module Y

**Workflow:**
```
1. Context7: "How does [module_Y] implement [feature_X]?"
2. Read results, understand pattern
3. Adapt pattern to current module
4. Test
```

**Example from today:**
```
Need: Query FalkorDB chunks
Context7: "How does Clerk query FalkorDB messages?"
Found: Individual property returns
Applied: Copied pattern for chunks
Result: SUCCESS
```

### Pattern 2: Debugging Dependencies

**Situation:** Unfamiliar library error (OpenAI, httpx, etc.)

**Workflow:**
```
1. Context7: "What is [library] [class/function] expected usage?"
2. Context7: "How do other projects use [library] [version]?"
3. Check official docs if needed
4. Apply correct usage
```

**Example from today:**
```
Error: AsyncClient 'proxies' parameter
Context7: "OpenAI AsyncClient initialization parameters"
Found: Version incompatibility (httpx 0.28+)
Applied: Pinned httpx==0.27.2
Result: FIXED
```

### Pattern 3: Understanding Complex Flows

**Situation:** LangGraph, async flows, state management confusion

**Workflow:**
```
1. Context7: "How does LangGraph StateGraph workflow work?"
2. Context7: "What happens to state between nodes?"
3. Draw mental diagram
4. Verify with logs
```

### Pattern 4: Consistency Validation

**Situation:** Unsure if approach is consistent with codebase

**Workflow:**
```
1. Context7: "How do other agents handle [scenario]?"
2. Compare approaches
3. Choose most common pattern
4. Apply consistently
```

**Example:**
```
Question: How to handle errors in node?
Context7: "How does Clerk handle errors in clerk_record_node?"
Found: Sets state["error"], returns state
Applied: Same in Subconscious
Result: Consistent error handling
```

---

## Testing Checklist Templates

### For New Agent Implementation

**Pre-implementation:**
- [ ] Architecture documented (.mdc file)
- [ ] State contract defined
- [ ] Dependencies identified
- [ ] Integration points clear

**Implementation:**
- [ ] All modules created
- [ ] No linter errors
- [ ] Dependencies added
- [ ] Config updated
- [ ] Workflow integrated

**Testing:**
- [ ] Docker builds successfully
- [ ] System starts without crash
- [ ] Browser test: happy path works
- [ ] Logs show expected flow
- [ ] Data in database correct
- [ ] Edge cases tested
- [ ] Performance acceptable

**Completion:**
- [ ] Structured commits (one per module)
- [ ] Documentation complete
- [ ] Pushed to remote
- [ ] TODO list updated

### For Bug Fix

**Diagnosis:**
- [ ] Error captured (logs saved)
- [ ] Root cause identified (file:line)
- [ ] Context understood (what led to error)
- [ ] Context7 consulted (working patterns)

**Fix:**
- [ ] ONE change at a time
- [ ] Follow existing patterns (Clerk, etc.)
- [ ] Comment if non-obvious
- [ ] No refactoring during bug fix

**Verification:**
- [ ] Rebuild + restart
- [ ] Re-test exact scenario
- [ ] Logs clean (no errors)
- [ ] Data valid in DB
- [ ] Test related scenarios

**Documentation:**
- [ ] Commit with clear message
- [ ] Add to "known issues" if relevant
- [ ] Update docs if behavior changed

---

## Playwright Best Practices

### Element Selection

```javascript
// 1. Get snapshot first
await browser_snapshot()

// 2. Find element by role/text
// ref=e44 for textbox
// ref=e48 for button

// 3. Use specific refs (not nth)
browser_click(element="Send button", ref="e48")  // âœ…
// Not: browser_click(button=5)  // âŒ Can break
```

### Waiting Strategies

```javascript
// For API operations
browser_wait_for(seconds=5)  // Subconscious ~2-5s

// For text to appear
browser_wait_for(text="Success")

// For text to disappear
browser_wait_for(textGone="Loading...")
```

### State Verification

```javascript
// After action
browser_snapshot()

// Check changes
// Look for: <changed> tags
// Look for: new elements
// Look for: [disabled] states
```

### Console Monitoring

**After browser action, check console:**
```
[LOG] - Expected operations
[ERROR] - Problems! Investigate
```

**Common console errors:**
- "Failed to load resource: 500" â†’ Backend error
- "Failed to send message" â†’ API error
- Network errors â†’ Connection issues

---

## Database Testing Patterns

### Query Templates

```cypher
-- Count nodes by type
MATCH (n) RETURN labels(n)[0] as type, count(n) ORDER BY count DESC

-- Inspect node properties
MATCH (n:Type) RETURN n.prop1, n.prop2 LIMIT 10

-- Check relationships
MATCH ()-[r:REL_TYPE]->() RETURN count(r)

-- Relationship properties
MATCH ()-[r:REL_TYPE]->() RETURN r.property LIMIT 10

-- Graph traversal
MATCH (n1)-[r]->(n2) RETURN type(r), count(*) GROUP BY type(r)

-- Temporal queries
MATCH (n) WHERE n.valid_at <= $time RETURN n
```

### Validation Queries

**After Subconscious processing:**
```cypher
-- 1. Chunks created?
MATCH (c:Chunk)-[:PART_OF]->(m:Message {id: $msg_id})
RETURN count(c)
-- Expected: 1-20 chunks depending on message length

-- 2. Embeddings exist?
MATCH (c:Chunk {message_id: $msg_id})
WHERE c.embedding IS NOT NULL
RETURN count(c)
-- Expected: Same as chunk count (all embedded)

-- 3. Entities extracted?
MATCH (m:Message {id: $msg_id})-[:DISCUSSES]->(e:Entity)
RETURN e.name, e.type, e.mention_count
-- Expected: 0-10 entities

-- 4. Similarity found?
MATCH (c1:Chunk {message_id: $msg_id})-[r:SIMILAR_TO]->(c2:Chunk)
RETURN c2.content, r.similarity
-- Expected: 0-10 similar chunks (if history exists)
```

---

## Error Recovery Strategies

### Strategy 1: Graceful Degradation

**Example: Embeddings fail**
```python
try:
    embeddings = await service.generate_batch(texts)
except EmbeddingError:
    # Continue without embeddings
    logger.warning("âš ï¸ Embeddings failed, semantic search disabled")
    embeddings = [None] * len(texts)
    # System continues!
```

**Benefits:**
- System doesn't crash
- User gets partial functionality
- Logs show what degraded

### Strategy 2: Retry with Backoff

**Example: API rate limit**
```python
for attempt in range(3):
    try:
        result = await api_call()
        break
    except RateLimitError:
        if attempt < 2:
            wait = 2 ** attempt  # 1s, 2s, 4s
            await asyncio.sleep(wait)
        else:
            raise  # Give up after 3 attempts
```

### Strategy 3: Fallback to Simpler Method

**Example: Similarity search fails**
```python
try:
    # Try semantic similarity
    similar = await find_similar_with_embeddings()
except:
    # Fallback: keyword matching
    similar = await find_similar_with_keywords()
```

---

## Lessons from Phase 2 Implementation

### âœ… What Worked Well

**1. Modular Implementation**
- 8 separate files, each with single responsibility
- Easy to test individually
- Easy to debug specific component

**2. Systematic Testing**
- Built everything first
- Tested end-to-end
- Fixed bugs one by one
- Verified in database

**3. Docker Logs**
- Detailed emoji logging (ğŸ“, ğŸ§ , ğŸ”)
- Step-by-step progress
- Clear error messages
- Timing information

**4. Context7 Usage**
- Found working patterns (Clerk queries)
- Understood FalkorDB format
- Copied proven approaches
- Avoided reinventing wheel

**5. Database Verification**
- redis-cli queries showed real data
- Validated entity merging (mention_count)
- Confirmed similarity relationships
- Proved system works end-to-end

### âŒ What Could Be Better

**1. Test Earlier**
- Could test text_processor independently
- Could test embeddings_service with mock
- Caught integration issues late

**2. Mock External APIs**
- Could mock OpenAI for faster iteration
- Real API = slower tests (2-5s per call)
- Rate limits can block testing

**3. Type Validation**
- Some type mismatches caught at runtime
- Could use mypy for static type checking

---

## Future Testing Enhancements

### Automated Test Suite

```python
# tests/integration/test_subconscious.py

@pytest.mark.playwright
async def test_subconscious_end_to_end(browser):
    """Full pipeline test through UI."""
    page = await browser.new_page()
    
    # Navigate
    await page.goto("http://localhost:3000/chat")
    
    # Type message
    await page.fill("textarea", "Docker test message")
    await page.click("button[type=submit]")
    
    # Wait for processing
    await page.wait_for_timeout(5000)
    
    # Verify in logs
    logs = get_backend_logs()
    assert "ğŸ§  ĞŸÑ–Ğ´ÑĞ²Ñ–Ğ´Ğ¾Ğ¼Ñ–ÑÑ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ»Ğ° Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·" in logs
    
    # Verify in DB
    chunks = query_db("MATCH (c:Chunk) RETURN count(c)")
    assert chunks > 0
```

### Mock OpenAI for Fast Tests

```python
@pytest.fixture
def mock_openai_embeddings():
    with patch('openai.embeddings.create') as mock:
        mock.return_value = [
            {"embedding": [0.1] * 1536}
        ]
        yield mock

async def test_embeddings_service(mock_openai_embeddings):
    service = EmbeddingsService()
    result = await service.generate("test")
    assert len(result) == 1536
    # Fast test without API call!
```

### Visual Regression Testing

```javascript
// Take screenshot
browser_take_screenshot(fullPage=true, filename="chat_page.png")

// Compare with baseline
// Tools: percy.io, chromatic, or simple image diff
```

---

## Quick Reference

### When Starting Test:
```
âœ… docker compose ps (all healthy?)
âœ… browser_navigate (page loads?)
âœ… browser_type + click (action works?)
âœ… docker compose logs (success logs?)
âœ… redis-cli GRAPH.QUERY (data saved?)
```

### When Debugging:
```
1. docker compose logs --tail 200
2. Find ERROR + Traceback
3. Context7: "How does [working_code] do this?"
4. Apply fix
5. Rebuild + test
```

### When Verifying:
```
âœ… HTTP 200 response
âœ… No console [ERROR]
âœ… Agent logs complete (âœ… emojis)
âœ… Data in DB valid
âœ… Performance acceptable
```

---

## Tools Summary

| Tool | When | Purpose |
|------|------|---------|
| **Playwright** | E2E testing | Realistic user behavior |
| **Context7** | Understanding/debugging | Learn patterns, find examples |
| **Docker logs** | Error diagnosis | Detailed tracebacks |
| **redis-cli** | Data verification | Validate graph state |
| **read_lints** | Pre-commit | Catch syntax errors |
| **grep** | Code search | Find specific patterns |

---

## Real-World Example (Phase 2 Today)

**Timeline:**

**18:00** - Implementation started  
**18:15** - All modules created (1890 lines)  
**18:20** - First test: Version error (httpx)  
**18:22** - Fixed requirements.txt  
**18:25** - Second test: State error  
**18:27** - Fixed nodes.py (use state directly)  
**18:30** - Third test: Query format error  
**18:32** - Context7: "How does Clerk query?"  
**18:34** - Fixed repository.py (property returns)  
**18:37** - Fourth test: F-string error  
**18:38** - Fixed nodes.py (extract variable)  
**18:40** - **SUCCESS!** All tests pass  
**18:45** - Database verification: all data correct  
**18:50** - 10 structured commits + push  

**Total:** ~50 minutes Ğ²Ñ–Ğ´ Ğ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ Ğ´Ğ¾ production-ready code!

**Key factors:**
- âœ… Systematic debugging
- âœ… Context7 for patterns
- âœ… Docker logs for tracing
- âœ… One fix at a time
- âœ… Verification after each fix

---

## Recommended Testing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. IMPLEMENT                       â”‚
â”‚     All modules + integration       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. BUILD                            â”‚
â”‚     docker compose build             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PLAYWRIGHT TEST                  â”‚
â”‚     browser_navigate + actions       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
         â”‚  Success? â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          YES  â”‚  NO
         â†“     â”‚     â†“
    â”Œâ”€â”€â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DB  â”‚    â”‚    â”‚  4. LOGS         â”‚
    â”‚CHECKâ”‚    â”‚    â”‚  docker logs     â”‚
    â””â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚         â†“
         â”‚     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     â”‚    â”‚  5. CONTEXT7     â”‚
         â”‚     â”‚    â”‚  Find patterns   â”‚
         â”‚     â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚         â†“
         â”‚     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     â”‚    â”‚  6. FIX          â”‚
         â”‚     â”‚    â”‚  One change      â”‚
         â”‚     â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚         â†“
         â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (rebuild & re-test)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. EDGE CASES                       â”‚
â”‚     Empty, long, special chars       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. COMMIT                           â”‚
â”‚     Structured commits + push        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Version:** 1.0.0  
**Created:** November 10, 2025  
**Based on:** Phase 2 Subconscious Agent testing experience  
**Validated:** Production deployment successful  
**Tools:** Playwright, Context7, Docker, redis-cli, linters
