---
description: Orchestrator Agent (–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä) patterns - Phase 3 (Not Yet Implemented)
alwaysApply: false
---
# ORCHESTRATOR AGENT (–û–†–ö–ï–°–¢–†–ê–¢–û–†) RULES

**Status:** üöß **NOT IMPLEMENTED** - —Ü–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–∞–π–±—É—Ç–Ω—å–æ—ó —ñ–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü—ñ—ó

---

## Purpose

–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä - —Ç—Ä–µ—Ç—ñ–π –∞–≥–µ–Ω—Ç, —è–∫–∏–π –ø—Ä–∏–π–º–∞—î —Ä—ñ—à–µ–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤—ñ–¥ –ü—ñ–¥—Å–≤—ñ–¥–æ–º–æ—Å—Ç—ñ —Ç–∞ –≥–µ–Ω–µ—Ä—É—î —Ñ—ñ–Ω–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É.

**–ú–µ—Ç–∞—Ñ–æ—Ä–∞:** –ö–æ–∑–∞—Ü—å–∫–∏–π –æ—Ç–∞–º–∞–Ω, —â–æ –ø—Ä–∏–π–º–∞—î —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–æ–∑–≤—ñ–¥–∫–∏.

---

## Responsibility

### ‚úÖ –¢–Ü–õ–¨–ö–ò –¶–ï:

1. **–û—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç** –≤—ñ–¥ Subconscious
2. **–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏** —â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —Ö–æ—á–µ
3. **–í–∏—Ä—ñ—à–∏—Ç–∏ –¥—ñ—é** (respond, search, clarify, use_tool)
4. **–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å** —á–µ—Ä–µ–∑ Gemini (—è–∫—â–æ respond)
5. **–í–∏–∫–ª–∏–∫–∞—Ç–∏ tools** (—è–∫—â–æ use_tool)
6. **–ó–∞–ø–∏—Å–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å** —á–µ—Ä–µ–∑ Clerk

### ‚ùå –ó–ê–ë–û–†–û–ù–ï–ù–û:

- ‚ùå –ü–∏—Å–∞—Ç–∏ –≤ –ë–î –Ω–∞–ø—Ä—è–º—É (—á–µ—Ä–µ–∑ Clerk!)
- ‚ùå –†–æ–±–∏—Ç–∏ context analysis (—Ü–µ Subconscious)
- ‚ùå –®—É–∫–∞—Ç–∏ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–ø—Ä—è–º—É (–∑–∞–ø–∏—Ç–∞–π Subconscious)

---

## Module Structure (Planned)

```
backend/app/agents/orchestrator/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ nodes.py              # orchestrator_decide_node, orchestrator_execute_node
‚îú‚îÄ‚îÄ router.py             # ActionRouter class
‚îú‚îÄ‚îÄ responder.py          # Response generation —á–µ—Ä–µ–∑ Gemini
‚îú‚îÄ‚îÄ tools.py              # Tool calling framework
‚îî‚îÄ‚îÄ schemas.py            # OrchestratorDecision, Action enum
```

---

## Action Types

### Action Enum

```python
from enum import Enum

class Action(str, Enum):
    RESPOND = "respond"              # –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    SEARCH = "search"                # –ü–æ—à—É–∫ –≤ knowledge base
    ASK_CLARIFICATION = "clarify"    # –ü–æ–ø—Ä–æ—Å–∏—Ç–∏ —É—Ç–æ—á–Ω–µ–Ω–Ω—è
    USE_TOOL = "tool"                # –í–∏–∫–ª–∏–∫–∞—Ç–∏ –∑–æ–≤–Ω—ñ—à–Ω—ñ–π tool
    DELEGATE = "delegate"            # –ü–µ—Ä–µ–¥–∞—Ç–∏ —ñ–Ω—à–æ–º—É –∞–≥–µ–Ω—Ç—É (future)
```

### Decision Logic

```python
async def decide_action(
    message: str,
    context: dict,
    related_count: int
) -> Action:
    """Decide what action to take."""
    
    # Rule-based (Phase 3.1)
    if "?" in message and related_count == 0:
        return Action.ASK_CLARIFICATION
    
    if "—à—É–∫–∞–π" in message.lower() or "find" in message.lower():
        return Action.SEARCH
    
    # Default
    return Action.RESPOND
    
    # Future (Phase 3.2): LLM-based decision
    # decision = await llm.decide(message, context)
```

---

## Response Generation

### Integration with GeminiService

```python
from app.services.gemini_service import GeminiService

async def generate_response(
    user_message: str,
    context: dict,
    gemini: GeminiService
) -> str:
    """Generate response using Gemini with context."""
    
    # Build prompt with context
    prompt = f"""
    User message: {user_message}
    
    Relevant context from history:
    {format_context(context)}
    
    Generate helpful response in Ukrainian.
    """
    
    # Call Gemini (—á–µ—Ä–µ–∑ —ñ—Å–Ω—É—é—á–∏–π CLI)
    response = await gemini.generate(prompt)
    
    return response
```

### Context Formatting

```python
def format_context(context: dict) -> str:
    """Format context for Gemini prompt."""
    
    parts = []
    
    # Recent messages
    if recent := context.get("recent_messages"):
        parts.append("Recent conversation:")
        for msg in recent[-3:]:  # Last 3
            parts.append(f"- {msg['role']}: {msg['content'][:100]}")
    
    # Topics
    if topics := context.get("topics"):
        parts.append(f"Topics discussed: {', '.join(topics)}")
    
    return "\n".join(parts)
```

---

## Node Implementation Pattern

```python
async def orchestrator_decide_node(
    state: dict,
    router: ActionRouter,
    gemini: GeminiService
) -> dict:
    """Decide action and execute."""
    
    logger.info("üéØ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: –ü—Ä–∏–π–º–∞—é —Ä—ñ—à–µ–Ω–Ω—è...")
    
    try:
        # 1. Get context from Subconscious
        context = state.get("context", {})
        message = state["message_content"]
        
        # 2. Decide action
        action = await router.decide(message, context)
        state["action"] = action.value
        
        logger.info(f"üéØ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: –í–∏—Ä—ñ—à–∏–≤ '{action.value}'")
        
        # 3. Execute action
        if action == Action.RESPOND:
            response = await generate_response(message, context, gemini)
            state["response"] = response
            
            # Record assistant message —á–µ—Ä–µ–∑ Clerk
            # (trigger new workflow with role="assistant")
        
        elif action == Action.SEARCH:
            results = await search_knowledge_base(message)
            state["search_results"] = results
            state["response"] = format_search_results(results)
        
        elif action == Action.ASK_CLARIFICATION:
            state["response"] = generate_clarification_question(message, context)
        
    except Exception as e:
        logger.error(f"üéØ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: –ü–æ–º–∏–ª–∫–∞: {e}")
        state["error"] = f"Decision failed: {e}"
        state["response"] = "–í–∏–±–∞—á—Ç–µ, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑."
    
    return state
```

---

## Recording Assistant Response

### Pattern (—á–µ—Ä–µ–∑ Clerk)

**WRONG:**
```python
# ‚ùå Orchestrator –ø–∏—à–µ –Ω–∞–ø—Ä—è–º—É –≤ –ë–î
await repository.create_message(assistant_msg)
```

**CORRECT:**
```python
# ‚úÖ –ß–µ—Ä–µ–∑ –æ–∫—Ä–µ–º–∏–π workflow
assistant_state = ChatState(
    message_content=state["response"],
    message_role="assistant",
    session_id=state["session_id"]
)

# –¢—Ä–∏–≥–µ—Ä Clerk –¥–ª—è assistant message
clerk_workflow = get_chat_workflow()  # Only Clerk
await clerk_workflow.ainvoke(assistant_state)
```

**WHY:** Clerk - —î–¥–∏–Ω–µ –¥–∂–µ—Ä–µ–ª–æ –ø—Ä–∞–≤–¥–∏ –¥–ª—è –∑–∞–ø–∏—Å—É. –í—Å—ñ —á–µ—Ä–µ–∑ –Ω—å–æ–≥–æ.

---

## Tool Calling Framework

### Tool Definition

```python
from typing import Protocol

class Tool(Protocol):
    name: str
    description: str
    
    async def execute(self, args: dict) -> dict:
        """Execute tool with arguments."""
        ...

# Example tools
class CalculatorTool:
    name = "calculator"
    description = "Perform math calculations"
    
    async def execute(self, args: dict) -> dict:
        expression = args["expression"]
        result = eval(expression)  # Safe eval!
        return {"result": result}

class SearchTool:
    name = "search"
    description = "Search in knowledge base"
    
    async def execute(self, args: dict) -> dict:
        query = args["query"]
        results = await search_db(query)
        return {"results": results}
```

### Tool Router

```python
class ToolRouter:
    def __init__(self):
        self.tools: dict[str, Tool] = {
            "calculator": CalculatorTool(),
            "search": SearchTool(),
        }
    
    async def execute_tool(self, tool_name: str, args: dict) -> dict:
        """Execute tool by name."""
        if tool_name not in self.tools:
            raise ValueError(f"Unknown tool: {tool_name}")
        
        tool = self.tools[tool_name]
        return await tool.execute(args)
```

---

## State Contract

### Orchestrator Receives

```python
# From Subconscious
state["context"] = {
    "recent_messages": [...],
    "similar_messages": [...],
    "topics": [...],
}
state["related_messages"] = [...]
state["semantic_similarity"] = 0.8
```

### Orchestrator Provides

```python
state["action"] = "respond|search|clarify|tool"
state["response"] = "Generated response text"
state["tool_used"] = "calculator"  # If tool was called
state["tool_result"] = {...}       # Tool output
```

---

## Decision Logic

### Rule-Based (Phase 3.1)

```python
class RuleBasedRouter:
    async def decide(self, message: str, context: dict) -> Action:
        """Simple rule-based routing."""
        
        # Questions without context ‚Üí clarify
        if "?" in message and not context.get("recent_messages"):
            return Action.ASK_CLARIFICATION
        
        # Math expressions ‚Üí use calculator
        if any(op in message for op in ["+", "-", "*", "/"]):
            return Action.USE_TOOL
        
        # Search keywords ‚Üí search
        if any(kw in message.lower() for kw in ["—à—É–∫–∞–π", "–∑–Ω–∞–π–¥–∏", "find"]):
            return Action.SEARCH
        
        # Default ‚Üí respond
        return Action.RESPOND
```

### LLM-Based (Phase 3.2)

```python
class LLMBasedRouter:
    async def decide(self, message: str, context: dict) -> Action:
        """Use Gemini to decide action."""
        
        prompt = f"""
        Decide action for this message:
        Message: {message}
        Context: {context}
        
        Choose one: respond, search, clarify, tool
        Respond with JSON: {{"action": "respond", "reasoning": "..."}}
        """
        
        result = await gemini.generate(prompt)
        decision = json.loads(result)
        
        return Action(decision["action"])
```

---

## Performance Targets

**Decision time:** < 100ms (rule-based) –∞–±–æ ~1s (LLM-based)  
**Response generation:** ~1-3s (Gemini API)  
**Tool execution:** varies (calculator ~1ms, search ~100ms)

**Total:** ~1-5 seconds per message (acceptable –¥–ª—è chat)

---

## Error Handling

### Graceful Degradation

```python
try:
    response = await generate_response(message, context, gemini)
except GeminiAPIError as e:
    logger.error(f"Gemini API failed: {e}")
    # Fallback
    response = "–í–∏–±–∞—á—Ç–µ, —Å—Ç–∞–ª–∞—Å—è —Ç–∏–º—á–∞—Å–æ–≤–∞ –ø—Ä–æ–±–ª–µ–º–∞. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ."

try:
    tool_result = await tool_router.execute(tool_name, args)
except ToolError as e:
    # Fallback to regular response
    response = await generate_response_without_tool(message, context)
```

---

## Integration Points

### With Existing GeminiService

```python
from app.services.gemini_service import GeminiService

# Existing service is for structuring
gemini = GeminiService()  

# We need chat generation
# Option 1: Extend GeminiService
async def generate_chat_response(
    self, 
    messages: list[dict],
    system_prompt: str
) -> str:
    """New method for chat."""
    ...

# Option 2: New service
class GeminiChatService:
    async def generate(self, prompt: str) -> str:
        """Generate conversational response."""
        ...
```

---

## Monitoring

### Key Metrics

1. **Action distribution** - % respond vs search vs tool
2. **Response quality** - user feedback (future)
3. **Latency** - time to generate response
4. **Error rate** - failed responses
5. **Context utilization** - —á–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—ñ–¥ Subconscious

---

## Testing Strategy

### Unit Tests

```python
@pytest.mark.asyncio
async def test_orchestrator_decide_respond():
    state = {
        "message_content": "–†–æ–∑–∫–∞–∂–∏ –ø—Ä–æ –∫–æ–∑–∞–∫—ñ–≤",
        "context": {"topics": ["history"]},
        "related_messages": ["msg1"]
    }
    
    result = await orchestrator_decide_node(state, mock_router, mock_gemini)
    
    assert result["action"] == "respond"
    assert result["response"] is not None
    assert "–∫–æ–∑–∞–∫" in result["response"].lower()
```

---

## Future: Multi-Turn Reasoning

### Chain of Thought

```python
# Orchestrator –º–æ–∂–µ –∑–∞–ø—É—Å–∫–∞—Ç–∏ sub-workflows
thought_process = [
    await think_step_1(message, context),
    await think_step_2(step1_result),
    await synthesize(step2_result)
]

final_response = thought_process[-1]
```

**For complex queries** —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –≥–ª–∏–±–æ–∫–æ–≥–æ reasoning.

---

**Version:** 0.1.0 (Planning)  
**Status:** NOT IMPLEMENTED  
**Blocked by:** Phase 2 (Subconscious)  
**Target:** Phase 3
