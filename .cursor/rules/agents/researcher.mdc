---
description: Researcher Agent (–î–æ—Å–ª—ñ–¥–Ω–∏–∫) - Text structuring research playground
alwaysApply: false
---
# RESEARCHER AGENT (–î–û–°–õ–Ü–î–ù–ò–ö) RULES

**Status:** ‚úÖ **EXISTS** as GeminiService - —Ü–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è —ñ—Å–Ω—É—é—á–æ–≥–æ —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—É

---

## Purpose

Researcher (–î–æ—Å–ª—ñ–¥–Ω–∏–∫) - —Ü–µ research playground –¥–ª—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ –∑ —Ä—ñ–∑–Ω–∏–º–∏ LLM –º–æ–¥–µ–ª—è–º–∏ —Ç–∞ –ø—ñ–¥—Ö–æ–¥–∞–º–∏ –¥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞–Ω–Ω—è –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É.

**NOT part of chat flow** - —Ü–µ standalone —Å–µ—Ä–≤—ñ—Å –∑ –≤–ª–∞—Å–Ω–∏–º UI –¥–ª—è —Ä—É—á–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤.

**–ú–µ—Ç–∞—Ñ–æ—Ä–∞:** –ö–æ–∑–∞—Ü—å–∫–∏–π —Ä–æ–∑–≤—ñ–¥–Ω–∏–∫, —â–æ –¥–æ—Å–ª—ñ–¥–∂—É—î —Ä—ñ–∑–Ω—ñ –ø—ñ–¥—Ö–æ–¥–∏ —Ç–∞ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –ø–µ—Ä–µ–¥ —Ç–∏–º —è–∫ –∑–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ –≤ –±–æ—é.

---

## Current Implementation

### Location

**Backend:**
- `backend/app/services/gemini_service.py` - GeminiService class
- `backend/app/api/routes.py` - /api/structure endpoint
- `backend/app/models/schemas.py` - StructuredDoc, ProcessingMetrics

**Frontend:**
- `frontend/src/pages/GeminiPage.tsx` - UI –¥–ª—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤
- `frontend/src/services/api.ts` - API client
- `frontend/src/components/TextInput.tsx` - Input –∑ model selector
- `frontend/src/components/SchemaBuilder.tsx` - Custom schema builder

### API Endpoints

**POST /api/structure**
```json
{
  "text": "–ù–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç...",
  "model": "gemini-2.5-flash",
  "custom_schema": "{...}"  // optional
}
```

**Response:**
```json
{
  "id": "uuid",
  "json_path": "data/uuid.json",
  "data": {...},  // Structured result
  "metrics": {
    "model": "gemini-2.5-flash",
    "processing_time_ms": 1234.56,
    "input_size": 500,
    "output_size": 250
  }
}
```

---

## Responsibilities

### ‚úÖ –©–û –†–û–ë–ò–¢–¨:

1. **–ü—Ä–∏–π–º–∞—î –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç** —Ç–∞ custom schema (optional)
2. **–ë—É–¥—É—î –ø—Ä–æ–º–ø—Ç** –∑ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è–º–∏ –¥–ª—è Gemini
3. **–í–∏–∫–ª–∏–∫–∞—î Gemini CLI** —á–µ—Ä–µ–∑ subprocess
4. **–ü–∞—Ä—Å–∏—Ç—å JSON** –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–≤–∏—Ç—è–≥—É—î –∑ markdown)
5. **–í–∞–ª—ñ–¥—É—î** —á–µ—Ä–µ–∑ Pydantic schema
6. **–ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç** –≤ `data/uuid.json` (atomic write)
7. **–ü–æ–≤–µ—Ä—Ç–∞—î –º–µ—Ç—Ä–∏–∫–∏** (timing, token counts, model info)

### ‚ùå –©–û –ù–ï –†–û–ë–ò–¢–¨:

- ‚ùå –ù–µ –∑–∞–ø–∏—Å—É—î –≤ FalkorDB (—Ç—ñ–ª—å–∫–∏ files)
- ‚ùå –ù–µ —ñ–Ω—Ç–µ–≥—Ä–æ–≤–∞–Ω–∏–π –≤ chat flow
- ‚ùå –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ —ñ—Å—Ç–æ—Ä—ñ—ó
- ‚ùå –ù–µ –ø—Ä–∏–π–º–∞—î —Ä—ñ—à–µ–Ω–Ω—è
- ‚ùå –ù–µ —î —á–∞—Å—Ç–∏–Ω–æ—é multi-agent pipeline

---

## –í—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤—ñ–¥ Chat Agents

| Aspect | Researcher | Clerk | Subconscious | Orchestrator |
|--------|-----------|-------|--------------|--------------|
| **–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è** | –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏ | –ó–∞–ø–∏—Å –≤ –ë–î | –ê–Ω–∞–ª—ñ–∑ | –†—ñ—à–µ–Ω–Ω—è |
| **–í chat flow?** | ‚ùå –ù—ñ | ‚úÖ –¢–∞–∫ | ‚úÖ –¢–∞–∫ | ‚úÖ –¢–∞–∫ |
| **LLM –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è** | ‚úÖ Heavy | ‚ùå –ù—ñ | ‚ö†Ô∏è Embeddings | ‚úÖ Generation |
| **UI** | ‚úÖ Dedicated | ‚ùå –ù—ñ | ‚ùå –ù—ñ | ‚ùå –ù—ñ |
| **Storage** | üìÅ Files | üóÑÔ∏è FalkorDB | üîó Relationships | üóÑÔ∏è via Clerk |
| **Latency** | ~1-5s | ~20ms | ~300ms | ~1-3s |
| **Manual/Auto** | üë§ Manual | ü§ñ Auto | ü§ñ Auto | ü§ñ Auto |

**Key difference:** Researcher - –¥–ª—è –ª—é–¥–∏–Ω–∏ (UI-driven), Chat agents - –¥–ª—è —Å–∏—Å—Ç–µ–º–∏ (event-driven).

---

## Current Features

### 1. Model Selection

```python
# In GeminiService
gemini_models = ["gemini-2.5-flash", "gemini-2.5-pro"]
```

**Frontend:**
- Dropdown –∑ –≤–∏–±–æ—Ä–æ–º –º–æ–¥–µ–ª—ñ
- Hints (15 RPM vs 2 RPM)

### 2. Custom Schema

**UI Schema Builder:**
- –í—ñ–∑—É–∞–ª—å–Ω–∏–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä JSON —Å—Ö–µ–º
- –ê—Ç–æ–º–∞—Ä–Ω–µ —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –ø–æ–ª—ñ–≤
- –¢–∏–ø–∏: string, number, boolean, array, object
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —à–∞–±–ª–æ–Ω—ñ–≤

### 3. Metrics Collection

```python
class ProcessingMetrics(BaseModel):
    model: str
    processing_time_ms: float
    input_size: int
    output_size: int
    estimated_input_tokens: int
    estimated_output_tokens: int
```

### 4. Error Handling

- CLIExecutionError - CLI failed
- JSONParsingError - Invalid JSON
- ValidationException - Schema mismatch

---

## Future Evolution (Roadmap)

### Phase Research.1: Multi-Model Support

**Add providers:**
```python
class ModelProvider(Enum):
    GEMINI = "gemini"           # Google (exists)
    OPENAI = "openai"           # GPT-4, GPT-4o
    ANTHROPIC = "anthropic"     # Claude
    OLLAMA = "ollama"           # Local models
    MISTRAL = "mistral"         # Mistral AI
```

**UI:**
- Provider selector
- Model selector per provider
- Side-by-side comparison (2-4 models)

**Implementation:**
```python
# services/model_providers/
‚îú‚îÄ‚îÄ base.py              # AbstractModelProvider
‚îú‚îÄ‚îÄ gemini.py            # GeminiProvider (existing)
‚îú‚îÄ‚îÄ openai.py            # OpenAIProvider (new)
‚îú‚îÄ‚îÄ anthropic.py         # AnthropicProvider (new)
‚îî‚îÄ‚îÄ ollama.py            # OllamaProvider (new)

class AbstractModelProvider:
    async def structure(self, text: str, schema: dict) -> dict:
        """Abstract method."""
        pass
```

### Phase Research.2: Prompt Engineering

**System prompt editor:**
```python
# –†–µ–¥–∞–≥—É–≤–∞—Ç–∏ –±–∞–∑–æ–≤–∏–π –ø—Ä–æ–º–ø—Ç
default_system_prompt = """
You are an expert at structuring text.
Convert the following text to JSON...
"""

# UI –¥–æ–∑–≤–æ–ª—è—î –∑–º—ñ–Ω—é–≤–∞—Ç–∏
custom_system_prompt = """
You are a Ukrainian history expert...
"""
```

**Prompt templates:**
- –ó–±–µ—Ä–µ–∂–µ–Ω—ñ –ø—Ä–æ–º–ø—Ç–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∑–∞–¥–∞—á
- Template variables: {schema}, {text}, {language}
- Versioning –ø—Ä–æ–º–ø—Ç—ñ–≤

**A/B Testing:**
```python
# –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –¥–≤–∞ –ø—Ä–æ–º–ø—Ç–∏ –Ω–∞ –æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—ñ
results = await compare_prompts(
    text=text,
    prompt_a=prompt_v1,
    prompt_b=prompt_v2,
    model="gemini-2.5-flash"
)
# Show differences, metrics
```

### Phase Research.3: Advanced Analytics

**Quality scoring:**
```python
class QualityMetrics(BaseModel):
    completeness: float     # 0-1, —á–∏ –≤—Å—ñ –ø–æ–ª—è –∑–∞–ø–æ–≤–Ω–µ–Ω—ñ
    accuracy: float         # Manual rating –∞–±–æ auto
    consistency: float      # Multiple runs consistency
    schema_compliance: bool # –í–∞–ª—ñ–¥–Ω–∏–π JSON schema
```

**Benchmark suite:**
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –Ω–∞–±—ñ—Ä —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
- –†—ñ–∑–Ω—ñ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ (simple, medium, complex)
- –†—ñ–∑–Ω—ñ –º–æ–≤–∏ (Ukrainian, English, mixed)
- –†—ñ–∑–Ω—ñ —Ç–∏–ø–∏ (article, contract, chat, email)

**Cost tracking:**
```python
class CostMetrics(BaseModel):
    input_tokens: int
    output_tokens: int
    cost_usd: float          # Based on provider pricing
    cost_per_1k_tokens: float
```

### Phase Research.4: Automation

**Batch processing:**
- Upload multiple files
- Process –∑ –æ–¥–Ω–∏–º schema
- Export aggregated results

**Scheduled experiments:**
- Nightly benchmarks
- Model regression testing
- Cost monitoring

---

## Technical Implementation

### Current Stack

```python
# GeminiService methods:
async def run_cli(prompt: str) -> tuple[str, float]
async def extract_json(raw_output: str) -> dict
async def validate_output(data: dict, schema: str | None) -> StructuredDoc
async def save_result(doc: StructuredDoc) -> tuple[str, Path]
async def structure_text(text: str, schema: str | None) -> tuple[...]
```

**Async-first:** –í—Å—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó —á–µ—Ä–µ–∑ asyncio.create_subprocess_exec

**Error handling:** Try-catch –Ω–∞ –∫–æ–∂–Ω–æ–º—É —Ä—ñ–≤–Ω—ñ –∑ –¥–µ—Ç–∞–ª—å–Ω–∏–º–∏ –ø–æ–º–∏–ª–∫–∞–º–∏

### Future Additions

**Multi-model abstraction:**
```python
class ResearchService:
    def __init__(self):
        self.providers = {
            "gemini": GeminiProvider(),
            "openai": OpenAIProvider(),
            "anthropic": AnthropicProvider(),
        }
    
    async def structure_with_model(
        self,
        text: str,
        model: str,
        provider: str,
        schema: dict | None = None
    ) -> StructuredResult:
        """Structure using specified model."""
        provider_service = self.providers[provider]
        return await provider_service.structure(text, schema)
    
    async def compare_models(
        self,
        text: str,
        models: list[tuple[str, str]],  # [(provider, model)]
        schema: dict | None = None
    ) -> list[ComparisonResult]:
        """Run same text through multiple models."""
        tasks = [
            self.structure_with_model(text, model, provider, schema)
            for provider, model in models
        ]
        return await asyncio.gather(*tasks)
```

---

## Storage Strategy

### Current (Files)

```
data/
‚îú‚îÄ‚îÄ abc123.json    # Structured result
‚îú‚îÄ‚îÄ def456.json
‚îî‚îÄ‚îÄ ...
```

**Pros:** Simple, no DB overhead  
**Cons:** Hard to query, no metadata search

### Future (Hybrid)

**Files + Results Database:**
```python
# Store results metadata in FalkorDB
(:ResearchRun {
  id: "uuid",
  model: "gemini-2.5-flash",
  provider: "gemini",
  timestamp: "...",
  input_length: 500,
  output_length: 250,
  processing_time: 1234.56,
  cost_usd: 0.002,
  quality_score: 0.85,
  file_path: "data/uuid.json"
})

// Relationships
(:ResearchRun)-[:USED_MODEL]->(:Model)
(:ResearchRun)-[:TESTED_SCHEMA]->(:Schema)
```

**Benefits:**
- Queryable —á–µ—Ä–µ–∑ Cypher
- Analytics —á–µ—Ä–µ–∑ graph
- History tracking
- Compare runs

---

## UI Enhancements (Future)

### Current (GeminiPage)

- Text input
- Model dropdown
- Schema builder
- JSON viewer
- Basic metrics

### Future (ResearchLab)

**Compare View:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Model 1: Gemini   ‚îÇ  Model 2: GPT-4   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Result JSON 1     ‚îÇ  Result JSON 2    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Time: 1.2s        ‚îÇ  Time: 2.5s       ‚îÇ
‚îÇ  Cost: $0.001      ‚îÇ  Cost: $0.005     ‚îÇ
‚îÇ  Quality: 0.85     ‚îÇ  Quality: 0.92    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Prompt Editor:**
- Syntax highlighting
- Variable substitution
- Template library
- Version control

**History View:**
- All past experiments
- Filter by model, date, quality
- Re-run with same params
- Export to CSV

---

## Testing Strategy

### Current

- ‚úÖ Manual testing —á–µ—Ä–µ–∑ UI
- ‚ö†Ô∏è No unit tests –¥–ª—è GeminiService
- ‚ö†Ô∏è No integration tests

### Future

**Unit tests:**
```python
@pytest.mark.asyncio
async def test_structure_text():
    service = GeminiService()
    result = await service.structure_text(
        text="John Doe, 30 years old",
        schema=person_schema
    )
    assert result.data["name"] == "John Doe"
    assert result.metrics.processing_time_ms > 0
```

**Benchmark tests:**
```python
@pytest.mark.benchmark
async def test_model_comparison():
    results = await compare_models(
        text=BENCHMARK_TEXT,
        models=[("gemini", "flash"), ("openai", "gpt-4o")]
    )
    assert len(results) == 2
    # Compare quality, timing, cost
```

---

## Configuration

### Current Settings

```python
# core/config.py
gemini_cli: str = "gemini"
gemini_model: str = "gemini-2.5-flash"
gemini_timeout: int = 300
gemini_models: list[str] = ["gemini-2.5-flash"]
default_output_dir: str = "data"
```

### Future Settings

```python
# Multi-provider config
class ResearchSettings:
    # Gemini (existing)
    gemini_api_key: str
    gemini_models: list[str]
    
    # OpenAI (future)
    openai_api_key: str
    openai_models: list[str] = ["gpt-4o", "gpt-4-turbo"]
    
    # Anthropic (future)
    anthropic_api_key: str
    anthropic_models: list[str] = ["claude-3-5-sonnet"]
    
    # Cost tracking
    track_costs: bool = True
    cost_limit_usd: float = 10.0  # Daily limit
```

---

## Performance Characteristics

### Current (Gemini Only)

**Model latencies:**
- gemini-2.5-flash: ~1-2s (15 RPM)
- gemini-2.5-pro: ~2-5s (2 RPM)

**Bottlenecks:**
- CLI spawn time: ~200-500ms
- Gemini API call: ~1-4s
- JSON parsing: ~10ms

### Future (Multi-Model)

**Expected latencies:**
- OpenAI GPT-4o: ~2-3s
- Claude Sonnet: ~1-3s
- Ollama (local): ~500ms-2s (depends on hardware)

**Optimization:**
- Parallel requests (asyncio.gather)
- Connection pooling (httpx.AsyncClient)
- Result caching (Redis)

---

## Use Cases

### 1. Model Evaluation

**Before adding to production:**
```
1. Test model with typical inputs
2. Compare quality vs cost vs speed
3. Identify failure modes
4. Choose optimal model
```

### 2. Prompt Optimization

**Find best prompt:**
```
1. Write baseline prompt
2. Create variations
3. A/B test on benchmark suite
4. Measure quality improvements
5. Deploy winner
```

### 3. Schema Development

**Design optimal schema:**
```
1. Try different field structures
2. Test required vs optional
3. Check validation errors
4. Iterate until robust
```

### 4. Cost Analysis

**Budget planning:**
```
1. Process sample dataset
2. Measure token usage
3. Calculate monthly cost
4. Choose cost-effective model
```

### 5. Quality Benchmarking

**Regression testing:**
```
1. Maintain benchmark suite
2. Run nightly on all models
3. Track quality over time
4. Detect degradations
```

---

## Integration Points

### Standalone (Current)

```
User ‚Üí GeminiPage UI ‚Üí /api/structure ‚Üí GeminiService ‚Üí Gemini CLI
```

**No integration** –∑ chat system.

### Possible Future: Tool for Orchestrator

```
Chat: "–°—Ç—Ä—É–∫—Ç—É—Ä—É–π —Ü–µ–π –¥–æ–∫—É–º–µ–Ω—Ç..."
    ‚Üì
Orchestrator detects need
    ‚Üì
    ‚îî‚îÄ‚îÄ‚Üí Researcher Tool (—á–µ—Ä–µ–∑ GeminiService)
         ‚Üê Structured result
    ‚Üì
Response: "–û—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç..."
```

**Decision:** –ü–æ–∫–∏ —â–æ standalone. –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è - Phase 4+.

---

## Lessons Learned (Current Implementation)

### Issue 1: CLI Output Contains Markdown

**Problem:** Gemini CLI wraps JSON –≤ markdown ```json...```

**Solution:**
```python
def extract_json(raw_output: str) -> dict:
    # Strip markdown fences
    if "```json" in raw_output:
        start = raw_output.find("```json") + 7
        end = raw_output.rfind("```")
        json_str = raw_output[start:end].strip()
    else:
        json_str = raw_output
    
    return json.loads(json_str)
```

### Issue 2: Gemini Sometimes Returns {"response": {...}}

**Problem:** Extra wrapper object

**Solution:**
```python
if "response" in parsed and len(parsed) == 1:
    parsed = parsed["response"]  # Unwrap
```

### Issue 3: Timeout for Long Texts

**Problem:** Default timeout (30s) –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤

**Solution:** Configurable timeout (300s default)

### Issue 4: Custom Schema Validation

**Problem:** User schema –º–æ–∂–µ –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—Ç–∏ –∑ StructuredDoc

**Solution:** Dynamic validation - —è–∫—â–æ —î custom_schema, –Ω–µ –≤–∞–ª—ñ–¥—É—î–º–æ —á–µ—Ä–µ–∑ StructuredDoc

---

## Future Enhancements

### Phase Research.1: Multi-Model Support

**Priority:** üî¥ High

**Tasks:**
- [ ] Abstract ModelProvider interface
- [ ] OpenAI provider (GPT-4o, GPT-4-turbo)
- [ ] Anthropic provider (Claude 3.5)
- [ ] Ollama provider (local models)
- [ ] Cost calculation per provider
- [ ] UI model selector (grouped by provider)

**Benefit:** Compare models before committing to one.

---

### Phase Research.2: Prompt Engineering Suite

**Priority:** üü° Medium

**Tasks:**
- [ ] System prompt editor in UI
- [ ] Prompt template library (save/load)
- [ ] Variable substitution ({schema}, {text}, {example})
- [ ] A/B testing framework (run 2+ prompts, compare)
- [ ] Prompt versioning (v1, v2, ...)
- [ ] Best prompt auto-suggestion

**Benefit:** Optimize prompts = better quality + lower cost.

---

### Phase Research.3: Benchmark & Analytics

**Priority:** üü° Medium

**Tasks:**
- [ ] Benchmark text suite (10-20 samples)
- [ ] Quality scoring (manual + auto)
- [ ] Model leaderboard (by quality, speed, cost)
- [ ] Regression testing (detect model changes)
- [ ] Export reports (CSV, PDF)
- [ ] Charts (quality over time, cost trends)

**Benefit:** Data-driven decisions, track improvements.

---

### Phase Research.4: Advanced Features

**Priority:** üü¢ Low (nice to have)

**Tasks:**
- [ ] Batch processing (upload CSV, process all)
- [ ] Incremental structuring (chunk long docs)
- [ ] Chain processing (structure ‚Üí enhance ‚Üí validate)
- [ ] Collaborative feedback (team ratings)
- [ ] Auto-detect optimal schema
- [ ] Generate schema from examples

**Benefit:** Professional research tool.

---

## Code Organization (Future Refactoring)

### Current Location

```
backend/app/services/gemini_service.py
```

### Future Location (Phase Research.1)

```
backend/app/agents/researcher/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ service.py                 # ResearchService (orchestrates providers)
‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îú‚îÄ‚îÄ base.py               # AbstractModelProvider
‚îÇ   ‚îú‚îÄ‚îÄ gemini.py             # GeminiProvider (refactored from GeminiService)
‚îÇ   ‚îú‚îÄ‚îÄ openai.py             # NEW
‚îÇ   ‚îú‚îÄ‚îÄ anthropic.py          # NEW
‚îÇ   ‚îî‚îÄ‚îÄ ollama.py             # NEW
‚îú‚îÄ‚îÄ schemas.py                # StructuredDoc, Metrics, ComparisonResult
‚îî‚îÄ‚îÄ benchmarks.py             # Benchmark suite
```

**Migration strategy:** 
- Create new structure
- Move GeminiService ‚Üí researcher/providers/gemini.py
- Keep backward compatibility (/api/structure unchanged)
- Deprecate old gradually

---

## API Evolution

### Current API

```
POST /api/structure
  - Single model
  - Single result
```

### Future API (Phase Research.1+)

```
POST /api/research/structure
  - Body: {text, model, provider, schema, system_prompt}
  - Response: Single result + metrics

POST /api/research/compare
  - Body: {text, models: [{provider, model}], schema}
  - Response: Array of results with comparison

GET /api/research/history
  - Response: Past experiments with filters

POST /api/research/benchmark
  - Body: {benchmark_id, models}
  - Response: Benchmark results

GET /api/research/models
  - Response: Available models per provider with pricing
```

---

## Monitoring & Observability

### Metrics to Track

1. **Usage metrics:**
   - Requests per day/hour
   - Models used (distribution)
   - Average processing time
   - Success rate

2. **Cost metrics:**
   - Total cost per day/month
   - Cost per model
   - Cost per user (if auth added)

3. **Quality metrics:**
   - Schema compliance rate
   - User satisfaction (ratings)
   - Error types distribution

### Dashboards (Future)

**Research Dashboard:**
- Model usage pie chart
- Cost over time line chart
- Quality trends
- Recent experiments table

---

## Security Considerations

### Current

- ‚úÖ Pydantic validation on input
- ‚úÖ CLI timeout limits
- ‚úÖ Output size limits (implicit —á–µ—Ä–µ–∑ Gemini)
- ‚ö†Ô∏è No rate limiting
- ‚ö†Ô∏è No auth (open access)

### Future

- [ ] API key per user
- [ ] Rate limiting (requests/hour)
- [ ] Cost limits per user
- [ ] Input sanitization (malicious prompts)
- [ ] Output filtering (sensitive data detection)

---

## Comparison: Researcher vs Other Services

### vs Clerk

**Clerk:** Records chat messages (real-time, DB)  
**Researcher:** Structures arbitrary text (on-demand, files)

### vs Template System

**Templates:** Structured input ‚Üí FalkorDB nodes  
**Researcher:** Unstructured text ‚Üí Structured JSON

### vs FalkorDB Service

**FalkorDB:** Graph operations (CRUD, query)  
**Researcher:** Text transformation (unstructured ‚Üí structured)

**All different purposes, minimal overlap.**

---

## Documentation TODOs

When implementing Research phases:

- [ ] Update this file –∑ patterns
- [ ] Document provider interfaces
- [ ] Add prompt engineering guidelines
- [ ] Benchmark suite documentation
- [ ] Cost calculation formulas
- [ ] Quality scoring methodology

---

## Notes

- **Keep standalone** - –Ω–µ —ñ–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –≤ chat flow (—Ä—ñ–∑–Ω–µ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è)
- **Focus on research** - —è–∫—ñ—Å—Ç—å, —à–≤–∏–¥–∫—ñ—Å—Ç—å, –≤–∞—Ä—Ç—ñ—Å—Ç—å, –Ω–µ production usage
- **UI-driven** - manual experimentation, not automated pipeline
- **Evolutionary approach** - –¥–æ–¥–∞—î–º–æ features –ø–æ –º—ñ—Ä—ñ –ø–æ—Ç—Ä–µ–±–∏
- **Document learnings** - –∫–æ–∂–µ–Ω –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç ‚Üí insights

---

## Quick Reference

**Current endpoint:** `POST /api/structure`  
**Current UI:** http://localhost:3000 (GeminiPage)  
**Current models:** Gemini Flash only  
**Current storage:** `data/*.json`

**Future focus:**
1. Multi-model support
2. Prompt engineering
3. Benchmarking
4. Cost tracking

---

**Version:** 1.0.0  
**Created:** November 6, 2025  
**Status:** Exists as GeminiService, roadmap for evolution  
**Next:** Phase Research.1 (Multi-Model) when needed
