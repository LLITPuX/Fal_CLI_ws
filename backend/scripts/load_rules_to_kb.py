"""
Load .cursor/rules files into Knowledge Base (cursor_memory graph).

This script performs ONE-TIME initialization of Knowledge Base with all rule files.
Should be run after validation passes.

Usage:
    python backend/scripts/load_rules_to_kb.py [--force-reload]
"""

import asyncio
import json
import hashlib
import re
from pathlib import Path
from typing import List, Dict
from datetime import datetime
import sys

# Add backend to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.db.falkordb.client import FalkorDBClient
from app.core.config import settings
import logging

logging.basicConfig(level=logging.INFO)


class KnowledgeBaseLoader:
    """Load rules files into FalkorDB Knowledge Base."""
    
    def __init__(self, rules_path: str = ".cursor/rules"):
        self.rules_path = Path(rules_path)
        self.kb_id = "cursor_rules_v3"
        self.kb_version = "3.0.0"
        self.client: FalkorDBClient | None = None
        self._client_created_here = False  # Track if we created the client
        self.stats = {
            "documents_created": 0,
            "chunks_created": 0,
            "errors": []
        }
    
    async def load_all(self, force_reload: bool = False):
        """
        Load all rule files into Knowledge Base.
        
        Args:
            force_reload: If True, clear existing KB and reload
        """
        print("[*] Knowledge Base Loader")
        print(f"    Target Graph: cursor_memory")
        print(f"    KB ID: {self.kb_id}")
        print(f"    KB Version: {self.kb_version}\n")
        
        # Initialize FalkorDB client if not already set
        if self.client is None:
            print("[+] Connecting to FalkorDB...")
            self.client = FalkorDBClient(
                host=settings.falkordb_host,
                port=settings.falkordb_port,
                graph_name="cursor_memory",
                max_query_time=60
            )
            self._client_created_here = True
            
            try:
                await self.client.connect()
                print(f"    [OK] Connected to FalkorDB\n")
            except Exception as e:
                print(f"    [ERROR] Failed to connect: {e}")
                return False
        else:
            print("[+] Using existing FalkorDB connection\n")
        
        # Load manifest
        manifest = self._load_manifest()
        
        if not manifest:
            print("[!] No manifest found. Run validate_rules.py first.")
            return False
        
        print(f"[*] Found {len(manifest)} files to load\n")
        
        # Step 1: Create/Check KnowledgeBase node
        if force_reload:
            print("[+] Force reload: clearing existing KB...")
            await self._clear_knowledge_base()
        
        kb_exists = await self._check_knowledge_base_exists()
        
        # Check if KB has documents
        if kb_exists:
            doc_count = await self._check_document_count()
            if doc_count > 0 and not force_reload:
                print(f"[!] Knowledge Base already exists with {doc_count} documents. Use --force-reload to overwrite.")
                return False
            elif doc_count == 0:
                print("[+] Knowledge Base exists but has no documents. Will load rules.")
        
        if not kb_exists:
            print("[+] Creating KnowledgeBase root node...")
            await self._create_knowledge_base()
        
        # Step 2: Load each document
        print(f"\n[+] Loading {len(manifest)} documents...")
        for idx, file_info in enumerate(manifest, 1):
            print(f"\n  [{idx}/{len(manifest)}] {file_info['relative_path']}")
            await self._load_document(file_info)
        
        # Step 3: Print summary
        self._print_summary()
        
        # Cleanup - only disconnect if we created the client
        if self._client_created_here:
            try:
                await self.client.disconnect()
            except Exception:
                pass
        
        return len(self.stats["errors"]) == 0
    
    def _load_manifest(self) -> List[Dict]:
        """Load manifest generated by validate_rules.py"""
        # Try container path first, then local path
        manifest_path = Path("/app/scripts/rules_manifest.json")
        if not manifest_path.exists():
            manifest_path = Path("backend/scripts/rules_manifest.json")
        
        if not manifest_path.exists():
            return []
        
        return json.loads(manifest_path.read_text(encoding="utf-8"))
    
    async def _check_knowledge_base_exists(self) -> bool:
        """Check if Knowledge Base already exists."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        RETURN kb
        """
        
        try:
            results, _ = await self.client.query(cypher, {"kb_id": self.kb_id})
            exists = len(results) > 0
            print(f"    [{'EXISTS' if exists else 'NEW'}] Knowledge Base")
            return exists
        except Exception as e:
            print(f"    [ERROR] Failed to check KB: {e}")
            return False
    
    async def _check_document_count(self) -> int:
        """Check how many documents are in the Knowledge Base."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})<-[:IN_BASE]-(d:Document)
        RETURN count(d) as doc_count
        """
        
        try:
            results, _ = await self.client.query(cypher, {"kb_id": self.kb_id})
            doc_count = results[0].get("doc_count", 0) if results else 0
            return doc_count
        except Exception as e:
            print(f"    [ERROR] Failed to check document count: {e}")
            return 0
    
    async def _create_knowledge_base(self):
        """Create KnowledgeBase root node."""
        cypher = """
        CREATE (kb:KnowledgeBase {
          id: $id,
          type: 'rules',
          version: $version,
          initialized_at: $timestamp,
          total_documents: 0,
          total_chunks: 0,
          status: 'loading'
        })
        RETURN kb.id as id
        """
        
        params = {
            "id": self.kb_id,
            "version": self.kb_version,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            await self.client.query(cypher, params)
            print("    [OK] Created KnowledgeBase node")
            print(f"    ID: {self.kb_id}")
            print(f"    Version: {self.kb_version}")
        except Exception as e:
            print(f"    [ERROR] Failed to create KB: {e}")
            raise
    
    async def _clear_knowledge_base(self):
        """Clear existing Knowledge Base (for force reload)."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        OPTIONAL MATCH (kb)<-[:IN_BASE]-(d:Document)
        OPTIONAL MATCH (d)<-[:PART_OF]-(c:Chunk)
        DETACH DELETE kb, d, c
        """
        
        try:
            await self.client.query(cypher, {"kb_id": self.kb_id})
            print("    [OK] Cleared existing KB")
        except Exception as e:
            print(f"    [ERROR] Failed to clear KB: {e}")
            raise
    
    async def _load_document(self, file_info: Dict):
        """Load single document with chunks."""
        try:
            # Read file content
            # Normalize paths - handle both Windows (backslash) and Unix (forward slash)
            file_path = None
            
            # Get relative_path and normalize separators
            rel_path = file_info.get("relative_path", "")
            if rel_path:
                # Convert Windows backslashes to forward slashes
                rel_path = rel_path.replace("\\", "/")
            
            # Strategy 1: Try container path using relative_path
            if rel_path:
                # Handle different relative_path formats
                if rel_path.startswith("rules/"):
                    # Format: rules/architecture.mdc -> /app/.cursor/rules/architecture.mdc
                    rules_part = rel_path.replace("rules/", "")
                    container_path = Path("/app/.cursor/rules") / rules_part
                    if container_path.exists():
                        file_path = container_path
                elif rel_path.startswith(".cursor/rules/"):
                    # Format: .cursor/rules/architecture.mdc -> /app/.cursor/rules/architecture.mdc
                    container_path = Path("/app") / rel_path
                    if container_path.exists():
                        file_path = container_path
            
            # Strategy 2: Try using path from manifest (normalize separators)
            if file_path is None or not file_path.exists():
                original_path_str = file_info.get("path", "")
                if original_path_str:
                    # Normalize path separators
                    original_path_str = original_path_str.replace("\\", "/")
                    # Extract .cursor/rules/... part
                    if ".cursor/rules/" in original_path_str:
                        rules_part = original_path_str.split(".cursor/rules/", 1)[-1]
                        container_path = Path("/app/.cursor/rules") / rules_part
                        if container_path.exists():
                            file_path = container_path
            
            # Strategy 3: Try direct container mount
            if file_path is None or not file_path.exists():
                if rel_path:
                    # Try to extract just the filename or subpath
                    if "/" in rel_path:
                        # Get the part after rules/
                        parts = rel_path.split("/")
                        if "rules" in parts:
                            idx = parts.index("rules")
                            if idx + 1 < len(parts):
                                subpath = "/".join(parts[idx + 1:])
                                container_path = Path("/app/.cursor/rules") / subpath
                                if container_path.exists():
                                    file_path = container_path
            
            if file_path is None or not file_path.exists():
                # Try to list what's actually in the directory for debugging
                rules_dir = Path("/app/.cursor/rules")
                available_files = []
                if rules_dir.exists():
                    try:
                        available_files = [str(p.relative_to(rules_dir)) for p in rules_dir.rglob("*.mdc")][:5]
                    except:
                        pass
                
                raise FileNotFoundError(
                    f"Could not find file: {file_info.get('path', 'unknown')} "
                    f"(relative_path: {file_info.get('relative_path', 'N/A')}). "
                    f"Available files (sample): {available_files}"
                )
            
            content = file_path.read_text(encoding="utf-8")
            
            print(f"    Size: {len(content)} bytes")
            print(f"    Category: {file_info['category']}")
            
            # Create Document node
            doc_id = await self._create_document_node(file_info, content)
            
            # Chunk content
            chunks = await self._chunk_content(content, file_info)
            print(f"    Chunks: {len(chunks)}")
            
            # Create Chunk nodes
            for chunk_idx, chunk in enumerate(chunks):
                await self._create_chunk_node(chunk, doc_id, chunk_idx)
            
            self.stats["documents_created"] += 1
            self.stats["chunks_created"] += len(chunks)
            
            print(f"    [OK] Loaded successfully")
            
        except Exception as e:
            error_msg = f"Failed to load {file_info['path']}: {e}"
            print(f"    [ERROR] {error_msg}")
            self.stats["errors"].append(error_msg)
    
    async def _create_document_node(self, file_info: Dict, content: str) -> str:
        """Create Document node in graph."""
        doc_id = f"doc_{file_info['content_hash'][:16]}"
        
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        CREATE (d:Document {
          id: $id,
          path: $path,
          relative_path: $relative_path,
          type: 'rules',
          category: $category,
          content_hash: $content_hash,
          version: $version,
          size_bytes: $size_bytes,
          lines: $lines,
          loaded_at: $timestamp,
          status: 'active',
          chunk_count: 0
        })
        CREATE (d)-[:IN_BASE]->(kb)
        RETURN d.id as id
        """
        
        params = {
            "kb_id": self.kb_id,
            "id": doc_id,
            "path": str(file_info["path"]),
            "relative_path": file_info["relative_path"],
            "category": file_info["category"],
            "content_hash": file_info["content_hash"],
            "version": file_info["version"],
            "size_bytes": file_info["size_bytes"],
            "lines": file_info["lines"],
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            results, _ = await self.client.query(cypher, params)
            return results[0]["id"] if results else doc_id
        except Exception as e:
            raise Exception(f"Failed to create document node: {e}")
    
    async def _chunk_content(self, content: str, file_info: Dict) -> List[Dict]:
        """Chunk content into semantic chunks (simple paragraph-based)."""
        chunks = []
        
        # Remove frontmatter
        content_without_frontmatter = re.sub(r'^---\s*\n.*?\n---\s*\n', '', content, flags=re.DOTALL)
        
        # Split by double newlines (paragraphs)
        paragraphs = content_without_frontmatter.split('\n\n')
        
        current_chunk = ""
        char_position = 0
        chunk_idx = 0
        
        for para in paragraphs:
            para = para.strip()
            if not para:
                continue
            
            # Determine chunk type
            chunk_type = self._detect_chunk_type(para)
            
            # If adding this para exceeds limit, save current chunk
            if current_chunk and len(current_chunk) + len(para) > 800:
                chunks.append({
                    "content": current_chunk.strip(),
                    "position": chunk_idx,
                    "char_start": char_position,
                    "char_end": char_position + len(current_chunk),
                    "chunk_type": chunk_type
                })
                char_position += len(current_chunk) + 2  # +2 for \n\n
                chunk_idx += 1
                current_chunk = ""
            
            current_chunk += para + "\n\n"
        
        # Add last chunk
        if current_chunk.strip():
            chunks.append({
                "content": current_chunk.strip(),
                "position": chunk_idx,
                "char_start": char_position,
                "char_end": char_position + len(current_chunk),
                "chunk_type": self._detect_chunk_type(current_chunk)
            })
        
        return chunks
    
    def _detect_chunk_type(self, text: str) -> str:
        """Detect chunk type based on content."""
        text_stripped = text.strip()
        
        if text_stripped.startswith('#'):
            return "heading"
        elif text_stripped.startswith('```'):
            return "code"
        elif text_stripped.startswith('-') or text_stripped.startswith('*'):
            return "list"
        elif len(text_stripped.split('\n')) == 1 and len(text_stripped) < 200:
            return "sentence"
        else:
            return "paragraph"
    
    async def _create_chunk_node(self, chunk: Dict, doc_id: str, position: int):
        """Create Chunk node in graph."""
        chunk_id = f"chunk_{hashlib.sha256(chunk['content'].encode()).hexdigest()[:16]}"
        
        cypher = """
        MATCH (d:Document {id: $doc_id})
        CREATE (c:Chunk {
          id: $id,
          content: $content,
          position: $position,
          char_start: $char_start,
          char_end: $char_end,
          chunk_type: $chunk_type,
          status: 'pending_vectorization',
          created_at: $timestamp
        })
        CREATE (c)-[:PART_OF {position: $position}]->(d)
        RETURN c.id as id
        """
        
        params = {
            "doc_id": doc_id,
            "id": chunk_id,
            "content": chunk["content"][:4000],  # Limit content length for FalkorDB
            "position": chunk["position"],
            "char_start": chunk["char_start"],
            "char_end": chunk["char_end"],
            "chunk_type": chunk["chunk_type"],
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            await self.client.query(cypher, params)
        except Exception as e:
            raise Exception(f"Failed to create chunk node: {e}")
    
    def _print_summary(self):
        """Print loading summary."""
        print("\n" + "="*60)
        print("LOADING SUMMARY")
        print("="*60 + "\n")
        
        print(f"[*] Statistics:")
        print(f"    Documents created: {self.stats['documents_created']}")
        print(f"    Chunks created: {self.stats['chunks_created']}")
        print(f"    Errors: {len(self.stats['errors'])}")
        
        if self.stats["errors"]:
            print(f"\n[!] Errors encountered:")
            for error in self.stats["errors"]:
                print(f"    - {error}")
        
        print("\n" + "="*60)
        
        if len(self.stats["errors"]) == 0:
            print("\n[SUCCESS] All files loaded successfully!")
            print("\n[*] Next steps:")
            print("    1. Async workers will process chunks (vectorization)")
            print("    2. Entity extraction will run")
            print("    3. Similarity links will be created")
            print("    4. Expected completion: ~10 minutes")
        else:
            print("\n[WARNING] Some files failed to load. Review errors above.")


async def main():
    """Main entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Load .cursor/rules into Knowledge Base"
    )
    parser.add_argument(
        "--force-reload",
        action="store_true",
        help="Clear existing KB and reload"
    )
    
    args = parser.parse_args()
    
    # Validation check
    manifest_path = Path("backend/scripts/rules_manifest.json")
    if not manifest_path.exists():
        print("[!] Manifest not found. Run validate_rules.py first:")
        print("    python backend/scripts/validate_rules.py")
        return 1
    
    # Load
    loader = KnowledgeBaseLoader()
    success = await loader.load_all(force_reload=args.force_reload)
    
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

