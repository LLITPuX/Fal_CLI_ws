"""
Load .cursor/rules files into Knowledge Base (cursor_memory graph).

This script performs ONE-TIME initialization of Knowledge Base with all rule files.
Should be run after validation passes.

Usage:
    python backend/scripts/load_rules_to_kb.py [--force-reload]
"""

import asyncio
import json
import hashlib
import re
from pathlib import Path
from typing import List, Dict
from datetime import datetime
import sys

# Add backend to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.db.falkordb.client import FalkorDBClient
from app.core.config import settings
from app.services.rule_parser_service import RuleParserService
from app.models.rule_schemas import RuleSchema
import logging

logging.basicConfig(level=logging.INFO)


class KnowledgeBaseLoader:
    """Load rules files into FalkorDB Knowledge Base."""
    
    def __init__(self, rules_path: str = ".cursor/rules"):
        self.rules_path = Path(rules_path)
        self.kb_id = "cursor_rules_v3"
        self.kb_version = "3.0.0"
        self.client: FalkorDBClient | None = None
        self._client_created_here = False  # Track if we created the client
        self.stats = {
            "documents_created": 0,
            "rules_created": 0,
            "entities_created": 0,
            "entity_rule_links_created": 0,
            "errors": []
        }
        self.rule_parser = RuleParserService()
    
    async def load_all(self, force_reload: bool = False):
        """
        Load all rule files into Knowledge Base.
        
        Args:
            force_reload: If True, clear existing KB and reload
        """
        print("[*] Knowledge Base Loader")
        print(f"    Target Graph: cursor_memory")
        print(f"    KB ID: {self.kb_id}")
        print(f"    KB Version: {self.kb_version}\n")
        
        # Initialize FalkorDB client if not already set
        if self.client is None:
            print("[+] Connecting to FalkorDB...")
            self.client = FalkorDBClient(
                host=settings.falkordb_host,
                port=settings.falkordb_port,
                graph_name="cursor_memory",
                max_query_time=60
            )
            self._client_created_here = True
            
            try:
                await self.client.connect()
                print(f"    [OK] Connected to FalkorDB\n")
            except Exception as e:
                print(f"    [ERROR] Failed to connect: {e}")
                return False
        else:
            print("[+] Using existing FalkorDB connection\n")
        
        # Load manifest
        manifest = self._load_manifest()
        
        if not manifest:
            print("[!] No manifest found. Run validate_rules.py first.")
            return False
        
        print(f"[*] Found {len(manifest)} files to load\n")
        
        # Step 1: Create/Check KnowledgeBase node
        if force_reload:
            print("[+] Force reload: clearing existing KB...")
            await self._clear_knowledge_base()
        
        kb_exists = await self._check_knowledge_base_exists()
        
        # Check if KB has documents
        if kb_exists:
            doc_count = await self._check_document_count()
            if doc_count > 0 and not force_reload:
                print(f"[!] Knowledge Base already exists with {doc_count} documents. Use --force-reload to overwrite.")
                return False
            elif doc_count == 0:
                print("[+] Knowledge Base exists but has no documents. Will load rules.")
        
        if not kb_exists:
            print("[+] Creating KnowledgeBase root node...")
            await self._create_knowledge_base()
        
        # Step 2: Load each document
        print(f"\n[+] Loading {len(manifest)} documents...")
        for idx, file_info in enumerate(manifest, 1):
            print(f"\n  [{idx}/{len(manifest)}] {file_info['relative_path']}")
            await self._load_document(file_info)
        
        # Step 3: Print summary
        self._print_summary()
        
        # Cleanup - only disconnect if we created the client
        if self._client_created_here:
            try:
                await self.client.disconnect()
            except Exception:
                pass
        
        return len(self.stats["errors"]) == 0
    
    def _load_manifest(self) -> List[Dict]:
        """Load manifest generated by validate_rules.py"""
        # Try container path first, then local path
        manifest_path = Path("/app/scripts/rules_manifest.json")
        if not manifest_path.exists():
            manifest_path = Path("backend/scripts/rules_manifest.json")
        
        if not manifest_path.exists():
            return []
        
        return json.loads(manifest_path.read_text(encoding="utf-8"))
    
    async def _check_knowledge_base_exists(self) -> bool:
        """Check if Knowledge Base already exists."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        RETURN kb
        """
        
        try:
            results, _ = await self.client.query(cypher, {"kb_id": self.kb_id})
            exists = len(results) > 0
            print(f"    [{'EXISTS' if exists else 'NEW'}] Knowledge Base")
            return exists
        except Exception as e:
            print(f"    [ERROR] Failed to check KB: {e}")
            return False
    
    async def _check_document_count(self) -> int:
        """Check how many documents are in the Knowledge Base."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})<-[:IN_BASE]-(d:Document)
        OPTIONAL MATCH (d)-[:CONTAINS]->(r:Rule)
        RETURN count(DISTINCT d) as doc_count, count(r) as rule_count
        """
        
        try:
            results, _ = await self.client.query(cypher, {"kb_id": self.kb_id})
            if results:
                doc_count = results[0].get("doc_count", 0)
                rule_count = results[0].get("rule_count", 0)
                # If we have documents but no rules, they're old chunk-based
                if doc_count > 0 and rule_count == 0:
                    print(f"    [INFO] Found {doc_count} documents with old chunk structure")
                    return 0  # Treat as empty for new structure
                return doc_count
            return 0
        except Exception as e:
            print(f"    [ERROR] Failed to check document count: {e}")
            return 0
    
    async def _create_knowledge_base(self):
        """Create KnowledgeBase root node."""
        cypher = """
        CREATE (kb:KnowledgeBase {
          id: $id,
          type: 'rules',
          version: $version,
          initialized_at: $timestamp,
          total_documents: 0,
          total_chunks: 0,
          status: 'loading'
        })
        RETURN kb.id as id
        """
        
        params = {
            "id": self.kb_id,
            "version": self.kb_version,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            await self.client.query(cypher, params)
            print("    [OK] Created KnowledgeBase node")
            print(f"    ID: {self.kb_id}")
            print(f"    Version: {self.kb_version}")
        except Exception as e:
            print(f"    [ERROR] Failed to create KB: {e}")
            raise
    
    async def _clear_knowledge_base(self):
        """Clear existing Knowledge Base (for force reload)."""
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        OPTIONAL MATCH (kb)<-[:IN_BASE]-(d:Document)
        OPTIONAL MATCH (d)<-[:CONTAINS]-(r:Rule)
        OPTIONAL MATCH (e:Entity)-[:HAS_RULE]->(r)
        DETACH DELETE kb, d, r, e
        """
        
        try:
            await self.client.query(cypher, {"kb_id": self.kb_id})
            print("    [OK] Cleared existing KB")
        except Exception as e:
            print(f"    [ERROR] Failed to clear KB: {e}")
            raise
    
    async def _load_document(self, file_info: Dict):
        """Load single document with chunks."""
        try:
            # Read file content
            # Normalize paths - handle both Windows (backslash) and Unix (forward slash)
            file_path = None
            
            # Get relative_path and normalize separators
            rel_path = file_info.get("relative_path", "")
            if rel_path:
                # Convert Windows backslashes to forward slashes
                rel_path = rel_path.replace("\\", "/")
            
            # Strategy 1: Try container path using relative_path
            if rel_path:
                # Handle different relative_path formats
                if rel_path.startswith("rules/"):
                    # Format: rules/architecture.mdc -> /app/.cursor/rules/architecture.mdc
                    rules_part = rel_path.replace("rules/", "")
                    container_path = Path("/app/.cursor/rules") / rules_part
                    if container_path.exists():
                        file_path = container_path
                elif rel_path.startswith(".cursor/rules/"):
                    # Format: .cursor/rules/architecture.mdc -> /app/.cursor/rules/architecture.mdc
                    container_path = Path("/app") / rel_path
                    if container_path.exists():
                        file_path = container_path
            
            # Strategy 2: Try using path from manifest (normalize separators)
            if file_path is None or not file_path.exists():
                original_path_str = file_info.get("path", "")
                if original_path_str:
                    # Normalize path separators
                    original_path_str = original_path_str.replace("\\", "/")
                    # Extract .cursor/rules/... part
                    if ".cursor/rules/" in original_path_str:
                        rules_part = original_path_str.split(".cursor/rules/", 1)[-1]
                        container_path = Path("/app/.cursor/rules") / rules_part
                        if container_path.exists():
                            file_path = container_path
            
            # Strategy 3: Try direct container mount
            if file_path is None or not file_path.exists():
                if rel_path:
                    # Try to extract just the filename or subpath
                    if "/" in rel_path:
                        # Get the part after rules/
                        parts = rel_path.split("/")
                        if "rules" in parts:
                            idx = parts.index("rules")
                            if idx + 1 < len(parts):
                                subpath = "/".join(parts[idx + 1:])
                                container_path = Path("/app/.cursor/rules") / subpath
                                if container_path.exists():
                                    file_path = container_path
            
            if file_path is None or not file_path.exists():
                # Try to list what's actually in the directory for debugging
                rules_dir = Path("/app/.cursor/rules")
                available_files = []
                if rules_dir.exists():
                    try:
                        available_files = [str(p.relative_to(rules_dir)) for p in rules_dir.rglob("*.mdc")][:5]
                    except:
                        pass
                
                raise FileNotFoundError(
                    f"Could not find file: {file_info.get('path', 'unknown')} "
                    f"(relative_path: {file_info.get('relative_path', 'N/A')}). "
                    f"Available files (sample): {available_files}"
                )
            
            content = file_path.read_text(encoding="utf-8")
            
            print(f"    Size: {len(content)} bytes")
            print(f"    Category: {file_info['category']}")
            
            # Create Document node
            doc_id = await self._create_document_node(file_info, content)
            
            # Parse document into rules using LLM
            print(f"    Parsing rules with LLM...")
            rules = await self.rule_parser.parse_document_to_rules(
                content, str(file_path)
            )
            print(f"    Rules extracted: {len(rules)}")
            
            # Create Rule nodes and entity links
            for rule in rules:
                rule_id = await self._create_rule_node(rule, doc_id, file_info)
                
                # Create/update Entity nodes and links
                for entity_name in rule.entities:
                    entity_id = await self._find_or_create_entity(entity_name)
                    
                    # Create links for each context
                    for context in rule.contexts:
                        await self._create_entity_rule_link(
                            entity_id, rule_id, context, rule.priority
                        )
            
            self.stats["documents_created"] += 1
            self.stats["rules_created"] += len(rules)
            
            print(f"    [OK] Loaded successfully")
            
        except Exception as e:
            error_msg = f"Failed to load {file_info['path']}: {e}"
            print(f"    [ERROR] {error_msg}")
            self.stats["errors"].append(error_msg)
    
    async def _create_document_node(self, file_info: Dict, content: str) -> str:
        """Create Document node in graph."""
        doc_id = f"doc_{file_info['content_hash'][:16]}"
        
        cypher = """
        MATCH (kb:KnowledgeBase {id: $kb_id})
        CREATE (d:Document {
          id: $id,
          path: $path,
          relative_path: $relative_path,
          type: 'rules',
          category: $category,
          content_hash: $content_hash,
          version: $version,
          size_bytes: $size_bytes,
          lines: $lines,
          loaded_at: $timestamp,
          status: 'active',
          chunk_count: 0
        })
        CREATE (d)-[:IN_BASE]->(kb)
        RETURN d.id as id
        """
        
        params = {
            "kb_id": self.kb_id,
            "id": doc_id,
            "path": str(file_info["path"]),
            "relative_path": file_info["relative_path"],
            "category": file_info["category"],
            "content_hash": file_info["content_hash"],
            "version": file_info["version"],
            "size_bytes": file_info["size_bytes"],
            "lines": file_info["lines"],
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            results, _ = await self.client.query(cypher, params)
            return results[0]["id"] if results else doc_id
        except Exception as e:
            raise Exception(f"Failed to create document node: {e}")
    
    async def _create_rule_node(self, rule: RuleSchema, doc_id: str, file_info: Dict) -> str:
        """Create Rule node in graph."""
        cypher = """
        MATCH (d:Document {id: $doc_id})
        MERGE (r:Rule {id: $id})
        ON CREATE SET
          r.title = $title,
          r.content = $content,
          r.rule_type = $rule_type,
          r.priority = $priority,
          r.source_section = $source_section,
          r.code_examples = $code_examples,
          r.contexts = $contexts,
          r.status = 'active',
          r.created_at = $timestamp
        ON MATCH SET
          r.title = $title,
          r.content = $content,
          r.rule_type = $rule_type,
          r.priority = $priority,
          r.source_section = $source_section,
          r.code_examples = $code_examples,
          r.contexts = $contexts
        MERGE (d)-[:CONTAINS]->(r)
        RETURN r.id as id
        """
        
        params = {
            "doc_id": doc_id,
            "id": rule.id,
            "title": rule.title,
            "content": rule.content[:8000],  # Limit for FalkorDB
            "rule_type": rule.rule_type,
            "priority": rule.priority,
            "source_section": rule.source_section,
            "code_examples": rule.code_examples[:5],  # Limit examples
            "contexts": rule.contexts,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            results, _ = await self.client.query(cypher, params)
            return results[0]["id"] if results else rule.id
        except Exception as e:
            raise Exception(f"Failed to create rule node: {e}")
    
    async def _find_or_create_entity(self, entity_name: str) -> str:
        """Find or create Entity node.
        
        Args:
            entity_name: Name of the entity
            
        Returns:
            Entity ID
        """
        # Normalize entity name
        canonical_name = entity_name.lower().strip()
        
        cypher = """
        MERGE (e:Entity {canonical_name: $canonical})
        ON CREATE SET
          e.id = $id,
          e.name = $name,
          e.canonical_name = $canonical,
          e.type = 'CONCEPT',
          e.mention_count = 1,
          e.first_seen = $timestamp,
          e.last_seen = $timestamp,
          e.status = 'active'
        ON MATCH SET
          e.mention_count = e.mention_count + 1,
          e.last_seen = $timestamp
        RETURN e.id as id
        """
        
        entity_id = f"entity_{hashlib.sha256(canonical_name.encode()).hexdigest()[:16]}"
        
        params = {
            "id": entity_id,
            "name": entity_name,
            "canonical": canonical_name,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # Check if entity exists first
            check_cypher = """
            MATCH (e:Entity {canonical_name: $canonical})
            RETURN e.id as id
            """
            check_results, _ = await self.client.query(check_cypher, {"canonical": canonical_name})
            entity_exists = len(check_results) > 0
            
            # Create or update
            results, _ = await self.client.query(cypher, params)
            entity_id_result = results[0]["id"] if results else entity_id
            
            # Track if this is a new entity
            if not entity_exists:
                self.stats["entities_created"] += 1
            
            return entity_id_result
        except Exception as e:
            raise Exception(f"Failed to find/create entity: {e}")
    
    async def _create_entity_rule_link(
        self, entity_id: str, rule_id: str, context: str, priority: str
    ):
        """Create HAS_RULE relationship between Entity and Rule.
        
        Args:
            entity_id: Entity node ID
            rule_id: Rule node ID
            context: Context where rule applies (frontend, backend, etc.)
            priority: Rule priority (high, medium, low)
        """
        cypher = """
        MATCH (e:Entity {id: $entity_id})
        MATCH (r:Rule {id: $rule_id})
        MERGE (e)-[link:HAS_RULE {context: $context}]->(r)
        ON CREATE SET
          link.priority = $priority,
          link.created_at = $timestamp,
          link.relevance = CASE 
            WHEN $priority = 'high' THEN 0.9
            WHEN $priority = 'medium' THEN 0.7
            ELSE 0.5
          END
        ON MATCH SET
          link.priority = $priority
        RETURN link
        """
        
        params = {
            "entity_id": entity_id,
            "rule_id": rule_id,
            "context": context,
            "priority": priority,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            await self.client.query(cypher, params)
            self.stats["entity_rule_links_created"] += 1
        except Exception as e:
            raise Exception(f"Failed to create entity-rule link: {e}")
    
    def _print_summary(self):
        """Print loading summary."""
        print("\n" + "="*60)
        print("LOADING SUMMARY")
        print("="*60 + "\n")
        
        print(f"[*] Statistics:")
        print(f"    Documents created: {self.stats['documents_created']}")
        print(f"    Rules created: {self.stats['rules_created']}")
        print(f"    Entities created: {self.stats['entities_created']}")
        print(f"    Entity-Rule links: {self.stats['entity_rule_links_created']}")
        print(f"    Errors: {len(self.stats['errors'])}")
        
        if self.stats["errors"]:
            print(f"\n[!] Errors encountered:")
            for error in self.stats["errors"]:
                print(f"    - {error}")
        
        print("\n" + "="*60)
        
        if len(self.stats["errors"]) == 0:
            print("\n[SUCCESS] All files loaded successfully!")
            print("\n[*] Knowledge Base structure:")
            print("    - Rules are linked to Documents")
            print("    - Entities are linked to Rules with contexts")
            print("    - Ready for querying: MATCH (e:Entity)-[:HAS_RULE]->(r:Rule)")
        else:
            print("\n[WARNING] Some files failed to load. Review errors above.")


async def main():
    """Main entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Load .cursor/rules into Knowledge Base"
    )
    parser.add_argument(
        "--force-reload",
        action="store_true",
        help="Clear existing KB and reload"
    )
    
    args = parser.parse_args()
    
    # Validation check
    manifest_path = Path("backend/scripts/rules_manifest.json")
    if not manifest_path.exists():
        print("[!] Manifest not found. Run validate_rules.py first:")
        print("    python backend/scripts/validate_rules.py")
        return 1
    
    # Load
    loader = KnowledgeBaseLoader()
    success = await loader.load_all(force_reload=args.force_reload)
    
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

